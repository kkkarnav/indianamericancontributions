{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 20\n",
    "df = f\"../data/CampaignFin{year}/indivs{year}.txt\"\n",
    "donors_csv = f\"../data/CampaignFin{year}/donors_state{year}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contrib_id</th>\n",
       "      <th>name</th>\n",
       "      <th>name_new</th>\n",
       "      <th>orgname</th>\n",
       "      <th>ultorg</th>\n",
       "      <th>realcode</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>employer</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>total_donated</th>\n",
       "      <th>donation_count</th>\n",
       "      <th>avg_donation</th>\n",
       "      <th>med_donation</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>ACTBLUE</td>\n",
       "      <td>actblue actblue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y4000</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>CA</td>\n",
       "      <td>1.261253e+09</td>\n",
       "      <td>25821</td>\n",
       "      <td>4.884603e+04</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>actblue</td>\n",
       "      <td>actblue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U00000037041</td>\n",
       "      <td>BLOOMBERG, MICHAEL R</td>\n",
       "      <td>michael r bloomberg</td>\n",
       "      <td>[Candidate Contribution]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z9000</td>\n",
       "      <td>M</td>\n",
       "      <td>FOUNDER</td>\n",
       "      <td>BLOOMBERG INC.</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>1.127731e+09</td>\n",
       "      <td>958</td>\n",
       "      <td>1.177172e+06</td>\n",
       "      <td>682.5</td>\n",
       "      <td>michael r</td>\n",
       "      <td>bloomberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U00000036521</td>\n",
       "      <td>STEYER, TOM</td>\n",
       "      <td>tom steyer</td>\n",
       "      <td>[Candidate Contribution]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z9000</td>\n",
       "      <td>M</td>\n",
       "      <td>PRESIDENTIAL CANDIDATE</td>\n",
       "      <td>SELF-EMPLOYED</td>\n",
       "      <td>SAN FRANCISCO</td>\n",
       "      <td>CA</td>\n",
       "      <td>3.794782e+08</td>\n",
       "      <td>756</td>\n",
       "      <td>5.019553e+05</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>tom</td>\n",
       "      <td>steyer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U00000046841</td>\n",
       "      <td>MELLON, TIMOTHY</td>\n",
       "      <td>timothy mellon</td>\n",
       "      <td>Investments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F7000</td>\n",
       "      <td>M</td>\n",
       "      <td>INVESTMENTS</td>\n",
       "      <td>SELF-EMPLOYED</td>\n",
       "      <td>SARATOGA</td>\n",
       "      <td>WY</td>\n",
       "      <td>4.513356e+07</td>\n",
       "      <td>23</td>\n",
       "      <td>1.962328e+06</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>timothy</td>\n",
       "      <td>mellon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U0000000310A</td>\n",
       "      <td>ADELSON, MIRIAM</td>\n",
       "      <td>miriam adelson</td>\n",
       "      <td>Adelson Clinic for Drug Abuse Treatment &amp; Rese...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H3200</td>\n",
       "      <td>F</td>\n",
       "      <td>PHYSICIAN</td>\n",
       "      <td>ADELSON CLINIC</td>\n",
       "      <td>LAS VEGAS</td>\n",
       "      <td>NV</td>\n",
       "      <td>4.499955e+07</td>\n",
       "      <td>124</td>\n",
       "      <td>3.628996e+05</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>miriam</td>\n",
       "      <td>adelson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U00000003101</td>\n",
       "      <td>ADELSON, SHELDON G</td>\n",
       "      <td>sheldon g adelson</td>\n",
       "      <td>Las Vegas Sands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G6500</td>\n",
       "      <td>M</td>\n",
       "      <td>CEO</td>\n",
       "      <td>LAS VEGAS SANDS CORPORATION</td>\n",
       "      <td>LAS VEGAS</td>\n",
       "      <td>NV</td>\n",
       "      <td>4.484795e+07</td>\n",
       "      <td>119</td>\n",
       "      <td>3.768735e+05</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>sheldon g</td>\n",
       "      <td>adelson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>U00000036901</td>\n",
       "      <td>UIHLEIN, RICHARD</td>\n",
       "      <td>richard uihlein</td>\n",
       "      <td>Uline Inc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M7000</td>\n",
       "      <td>M</td>\n",
       "      <td>CEO</td>\n",
       "      <td>ULINE</td>\n",
       "      <td>LAKE FOREST</td>\n",
       "      <td>IL</td>\n",
       "      <td>3.536433e+07</td>\n",
       "      <td>319</td>\n",
       "      <td>1.108600e+05</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>richard</td>\n",
       "      <td>uihlein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>U00000036551</td>\n",
       "      <td>GRIFFIN, KENNETH</td>\n",
       "      <td>kenneth griffin</td>\n",
       "      <td>Citadel LLC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F2700</td>\n",
       "      <td>M</td>\n",
       "      <td>FOUNDER  CEO</td>\n",
       "      <td>CITADEL LLC</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>IL</td>\n",
       "      <td>3.366763e+07</td>\n",
       "      <td>188</td>\n",
       "      <td>1.790832e+05</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>kenneth</td>\n",
       "      <td>griffin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>U00000003611</td>\n",
       "      <td>SCHWARZMAN, STEPHEN A</td>\n",
       "      <td>stephen a schwarzman</td>\n",
       "      <td>Blackstone Group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F2600</td>\n",
       "      <td>M</td>\n",
       "      <td>CHAIRMAN</td>\n",
       "      <td>BLACKSTONE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>3.345400e+07</td>\n",
       "      <td>226</td>\n",
       "      <td>1.480265e+05</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>stephen a</td>\n",
       "      <td>schwarzman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>U00000046781</td>\n",
       "      <td>JURVETSON, KARLA</td>\n",
       "      <td>karla jurvetson</td>\n",
       "      <td>Karla T Jurvetson MD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H1110</td>\n",
       "      <td>F</td>\n",
       "      <td>PHYSICIAN</td>\n",
       "      <td>SELF</td>\n",
       "      <td>LOS ALTOS</td>\n",
       "      <td>CA</td>\n",
       "      <td>3.308810e+07</td>\n",
       "      <td>914</td>\n",
       "      <td>3.620142e+04</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>karla</td>\n",
       "      <td>jurvetson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     contrib_id                   name              name_new  \\\n",
       "0                              ACTBLUE       actblue actblue   \n",
       "1  U00000037041   BLOOMBERG, MICHAEL R   michael r bloomberg   \n",
       "2  U00000036521            STEYER, TOM            tom steyer   \n",
       "3  U00000046841        MELLON, TIMOTHY        timothy mellon   \n",
       "4  U0000000310A        ADELSON, MIRIAM        miriam adelson   \n",
       "5  U00000003101     ADELSON, SHELDON G     sheldon g adelson   \n",
       "6  U00000036901       UIHLEIN, RICHARD       richard uihlein   \n",
       "7  U00000036551       GRIFFIN, KENNETH       kenneth griffin   \n",
       "8  U00000003611  SCHWARZMAN, STEPHEN A  stephen a schwarzman   \n",
       "9  U00000046781       JURVETSON, KARLA       karla jurvetson   \n",
       "\n",
       "                                             orgname ultorg realcode gender  \\\n",
       "0                                                NaN    NaN    Y4000          \n",
       "1                           [Candidate Contribution]    NaN    Z9000      M   \n",
       "2                           [Candidate Contribution]    NaN    Z9000      M   \n",
       "3                                        Investments    NaN    F7000      M   \n",
       "4  Adelson Clinic for Drug Abuse Treatment & Rese...    NaN    H3200      F   \n",
       "5                                    Las Vegas Sands    NaN    G6500      M   \n",
       "6                                          Uline Inc    NaN    M7000      M   \n",
       "7                                        Citadel LLC    NaN    F2700      M   \n",
       "8                                   Blackstone Group    NaN    F2600      M   \n",
       "9                               Karla T Jurvetson MD    NaN    H1110      F   \n",
       "\n",
       "               occupation                     employer           city state  \\\n",
       "0                     NaN                          NaN     WASHINGTON    CA   \n",
       "1                 FOUNDER               BLOOMBERG INC.       NEW YORK    NY   \n",
       "2  PRESIDENTIAL CANDIDATE                SELF-EMPLOYED  SAN FRANCISCO    CA   \n",
       "3             INVESTMENTS                SELF-EMPLOYED       SARATOGA    WY   \n",
       "4               PHYSICIAN               ADELSON CLINIC      LAS VEGAS    NV   \n",
       "5                     CEO  LAS VEGAS SANDS CORPORATION      LAS VEGAS    NV   \n",
       "6                     CEO                        ULINE    LAKE FOREST    IL   \n",
       "7            FOUNDER  CEO                  CITADEL LLC        CHICAGO    IL   \n",
       "8                CHAIRMAN                   BLACKSTONE       NEW YORK    NY   \n",
       "9               PHYSICIAN                         SELF      LOS ALTOS    CA   \n",
       "\n",
       "   total_donated  donation_count  avg_donation  med_donation  firstname  \\\n",
       "0   1.261253e+09           25821  4.884603e+04        1000.0    actblue   \n",
       "1   1.127731e+09             958  1.177172e+06         682.5  michael r   \n",
       "2   3.794782e+08             756  5.019553e+05        2800.0        tom   \n",
       "3   4.513356e+07              23  1.962328e+06        2800.0    timothy   \n",
       "4   4.499955e+07             124  3.628996e+05        2800.0     miriam   \n",
       "5   4.484795e+07             119  3.768735e+05        2800.0  sheldon g   \n",
       "6   3.536433e+07             319  1.108600e+05        2800.0    richard   \n",
       "7   3.366763e+07             188  1.790832e+05        2800.0    kenneth   \n",
       "8   3.345400e+07             226  1.480265e+05        2800.0  stephen a   \n",
       "9   3.308810e+07             914  3.620142e+04        2800.0      karla   \n",
       "\n",
       "     lastname  \n",
       "0     actblue  \n",
       "1   bloomberg  \n",
       "2      steyer  \n",
       "3      mellon  \n",
       "4     adelson  \n",
       "5     adelson  \n",
       "6     uihlein  \n",
       "7     griffin  \n",
       "8  schwarzman  \n",
       "9   jurvetson  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors = pd.read_csv(donors_csv)\n",
    "donors[\"firstname\"] = donors[\"name\"].apply(lambda x: str(x).split(\",\")[-1].lower().strip())\n",
    "donors[\"lastname\"] = donors[\"name\"].apply(lambda x: str(x).split(\",\")[0].lower().strip())\n",
    "donors.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstname_ratios = pd.read_csv(\"../output/USIN_firstnames_ratios.csv\")\n",
    "lastname_ratios = pd.read_csv(\"../output/USIN_lastnames_ratios.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstname_ratio_dict = firstname_ratios.set_index(firstname_ratios['firstname'].str.strip().str.lower())['ratio'].to_dict()\n",
    "lastname_ratio_dict = lastname_ratios.set_index(lastname_ratios['lastname'].str.strip().str.lower())['ratio'].to_dict()\n",
    "\n",
    "donors['combined_ratio'] = (\n",
    "    donors['firstname'].map(firstname_ratio_dict).fillna(0) + \n",
    "    donors['lastname'].map(lastname_ratio_dict).fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most common indian last names\n",
    "indian_firstnames = set(firstname_ratios[firstname_ratios[\"ratio\"] >= 8][\"firstname\"].str.lower())\n",
    "indian_lastnames = set(lastname_ratios[lastname_ratios[\"ratio\"] >= 5][\"lastname\"].str.lower())\n",
    "unindian_firstnames = set(firstname_ratios[firstname_ratios[\"ratio\"] <= 0.05][\"firstname\"].str.lower())\n",
    "unindian_lastnames = set(lastname_ratios[lastname_ratios[\"ratio\"] <= 0.05][\"lastname\"].str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indian\n",
       "False    3545523\n",
       "True       43413\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors[\"indian_first\"] = np.where(donors[\"firstname\"].str.lower().isin(indian_firstnames) & ~donors[\"lastname\"].str.lower().isin(unindian_lastnames), True, False)\n",
    "donors[\"indian_last\"] = np.where(donors[\"lastname\"].str.lower().isin(indian_lastnames) & ~donors[\"firstname\"].str.lower().isin(unindian_firstnames), True, False)\n",
    "donors[\"indian\"] = np.where((donors[\"combined_ratio\"] >= 15) | (donors[\"indian_first\"] == True) | (donors[\"indian_last\"] == True), True, False)\n",
    "donors[\"indian\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_us = pd.read_csv(\"../data/US.csv\")\\ndf_us.columns = [\\'firstname\\', \\'lastname\\', \\'gender\\', \\'ethnicity\\']\\ndf_us[\\'firstname\\'] = df_us[\\'firstname\\'].apply(lambda x: x.split(\" \")[0].strip() if \" \" in str(x) else str(x).strip())\\ndf_us[\\'lastname\\'] = df_us[\\'lastname\\'].apply(lambda x: x.split(\" \")[-1].strip() if \" \" in str(x) else str(x).strip())\\ndf_us[\\'name\\'] = df_us[\\'firstname\\'].apply(lambda x: x.lower()) + \\' \\' + df_us[\\'lastname\\'].apply(lambda x: x.lower())\\ndf_us[\"indian\"] = df_us[\"ethnicity\"].apply(lambda x: False)\\n\\ndf_us = df_us[\\n    (df_us[\\'firstname\\'].str.match(r\\'^[A-Za-z]+$\\', na=False)) & \\n    (df_us[\\'firstname\\'].str.len() > 1) &\\n    (df_us[\\'firstname\\'].str.lower() != \\'nan\\') &\\n    (df_us[\\'lastname\\'].str.match(r\\'^[A-Za-z]+$\\', na=False)) &\\n    (df_us[\\'lastname\\'].str.len() > 1) &\\n    (df_us[\\'lastname\\'].str.lower() != \\'nan\\')\\n]\\n\\ndf_us = df_us[[\\'firstname\\', \\'lastname\\', \\'name\\', \\'indian\\']]\\ndf_us.head(10)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/philipperemy/name-dataset\n",
    "'''df_us = pd.read_csv(\"../data/US.csv\")\n",
    "df_us.columns = ['firstname', 'lastname', 'gender', 'ethnicity']\n",
    "df_us['firstname'] = df_us['firstname'].apply(lambda x: x.split(\" \")[0].strip() if \" \" in str(x) else str(x).strip())\n",
    "df_us['lastname'] = df_us['lastname'].apply(lambda x: x.split(\" \")[-1].strip() if \" \" in str(x) else str(x).strip())\n",
    "df_us['name'] = df_us['firstname'].apply(lambda x: x.lower()) + ' ' + df_us['lastname'].apply(lambda x: x.lower())\n",
    "df_us[\"indian\"] = df_us[\"ethnicity\"].apply(lambda x: False)\n",
    "\n",
    "df_us = df_us[\n",
    "    (df_us['firstname'].str.match(r'^[A-Za-z]+$', na=False)) & \n",
    "    (df_us['firstname'].str.len() > 1) &\n",
    "    (df_us['firstname'].str.lower() != 'nan') &\n",
    "    (df_us['lastname'].str.match(r'^[A-Za-z]+$', na=False)) &\n",
    "    (df_us['lastname'].str.len() > 1) &\n",
    "    (df_us['lastname'].str.lower() != 'nan')\n",
    "]\n",
    "\n",
    "df_us = df_us[['firstname', 'lastname', 'name', 'indian']]\n",
    "df_us.head(10)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"total_names = len(df_us)\\n\\nfirstname_counts = df_us['firstname'].value_counts().reset_index().rename(columns={'count': 'firstname_count'})\\nfirstname_counts['firstname_rate'] = (firstname_counts['firstname_count'] / len(df_us)) * 100\\n\\nlastname_counts = df_us['lastname'].value_counts().reset_index().rename(columns={'count': 'lastname_count'})\\nlastname_counts['lastname_rate'] = (lastname_counts['lastname_count'] / len(df_us)) * 100\\n\\ndf_us = df_us.merge(firstname_counts[['firstname', 'firstname_count', 'firstname_rate']], on='firstname', how='left')\\ndf_us = df_us.merge(lastname_counts[['lastname', 'lastname_count', 'lastname_rate']], on='lastname', how='left')\\ndf_us\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''total_names = len(df_us)\n",
    "\n",
    "firstname_counts = df_us['firstname'].value_counts().reset_index().rename(columns={'count': 'firstname_count'})\n",
    "firstname_counts['firstname_rate'] = (firstname_counts['firstname_count'] / len(df_us)) * 100\n",
    "\n",
    "lastname_counts = df_us['lastname'].value_counts().reset_index().rename(columns={'count': 'lastname_count'})\n",
    "lastname_counts['lastname_rate'] = (lastname_counts['lastname_count'] / len(df_us)) * 100\n",
    "\n",
    "df_us = df_us.merge(firstname_counts[['firstname', 'firstname_count', 'firstname_rate']], on='firstname', how='left')\n",
    "df_us = df_us.merge(lastname_counts[['lastname', 'lastname_count', 'lastname_rate']], on='lastname', how='left')\n",
    "df_us'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# https://github.com/philipperemy/name-dataset\\ndf_indian = pd.read_csv(\"../data/IN.csv\")\\ndf_indian.columns = [\\'firstname\\', \\'lastname\\', \\'gender\\', \\'ethnicity\\']\\ndf_indian[\\'firstname\\'] = df_indian[\\'firstname\\'].apply(lambda x: x.split(\" \")[0].strip() if \" \" in str(x) else str(x).strip())\\ndf_indian[\\'lastname\\'] = df_indian[\\'lastname\\'].apply(lambda x: x.split(\" \")[-1].strip() if \" \" in str(x) else str(x).strip())\\ndf_indian[\\'name\\'] = df_indian[\\'firstname\\'].apply(lambda x: x.lower()) + \\' \\' + df_indian[\\'lastname\\'].apply(lambda x: x.lower())\\ndf_indian[\"indian\"] = df_indian[\"ethnicity\"].apply(lambda x: True)\\n\\ndf_indian = df_indian[\\n    (df_indian[\\'firstname\\'].str.match(r\\'^[A-Za-z]+$\\', na=False)) & \\n    (df_indian[\\'firstname\\'].str.len() > 1) &\\n    (df_indian[\\'firstname\\'].str.lower() != \\'nan\\') &\\n    (df_indian[\\'lastname\\'].str.match(r\\'^[A-Za-z]+$\\', na=False)) &\\n    (df_indian[\\'lastname\\'].str.len() > 1) &\\n    (df_indian[\\'lastname\\'].str.lower() != \\'nan\\')\\n]\\n\\ndf_indian = df_indian[[\\'firstname\\', \\'lastname\\', \\'name\\', \\'indian\\']]\\ndf_indian.head(10)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# https://github.com/philipperemy/name-dataset\n",
    "df_indian = pd.read_csv(\"../data/IN.csv\")\n",
    "df_indian.columns = ['firstname', 'lastname', 'gender', 'ethnicity']\n",
    "df_indian['firstname'] = df_indian['firstname'].apply(lambda x: x.split(\" \")[0].strip() if \" \" in str(x) else str(x).strip())\n",
    "df_indian['lastname'] = df_indian['lastname'].apply(lambda x: x.split(\" \")[-1].strip() if \" \" in str(x) else str(x).strip())\n",
    "df_indian['name'] = df_indian['firstname'].apply(lambda x: x.lower()) + ' ' + df_indian['lastname'].apply(lambda x: x.lower())\n",
    "df_indian[\"indian\"] = df_indian[\"ethnicity\"].apply(lambda x: True)\n",
    "\n",
    "df_indian = df_indian[\n",
    "    (df_indian['firstname'].str.match(r'^[A-Za-z]+$', na=False)) & \n",
    "    (df_indian['firstname'].str.len() > 1) &\n",
    "    (df_indian['firstname'].str.lower() != 'nan') &\n",
    "    (df_indian['lastname'].str.match(r'^[A-Za-z]+$', na=False)) &\n",
    "    (df_indian['lastname'].str.len() > 1) &\n",
    "    (df_indian['lastname'].str.lower() != 'nan')\n",
    "]\n",
    "\n",
    "df_indian = df_indian[['firstname', 'lastname', 'name', 'indian']]\n",
    "df_indian.head(10)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"total_names = len(df_indian)\\n\\nfirstname_counts = df_indian['firstname'].value_counts().reset_index().rename(columns={'count': 'firstname_count'})\\nfirstname_counts['firstname_rate'] = (firstname_counts['firstname_count'] / len(df_indian)) * 100\\n\\nlastname_counts = df_indian['lastname'].value_counts().reset_index().rename(columns={'count': 'lastname_count'})\\nlastname_counts['lastname_rate'] = (lastname_counts['lastname_count'] / len(df_indian)) * 100\\n\\ndf_indian = df_indian.merge(firstname_counts[['firstname', 'firstname_count', 'firstname_rate']], on='firstname', how='left')\\ndf_indian = df_indian.merge(lastname_counts[['lastname', 'lastname_count', 'lastname_rate']], on='lastname', how='left')\\ndf_indian\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''total_names = len(df_indian)\n",
    "\n",
    "firstname_counts = df_indian['firstname'].value_counts().reset_index().rename(columns={'count': 'firstname_count'})\n",
    "firstname_counts['firstname_rate'] = (firstname_counts['firstname_count'] / len(df_indian)) * 100\n",
    "\n",
    "lastname_counts = df_indian['lastname'].value_counts().reset_index().rename(columns={'count': 'lastname_count'})\n",
    "lastname_counts['lastname_rate'] = (lastname_counts['lastname_count'] / len(df_indian)) * 100\n",
    "\n",
    "df_indian = df_indian.merge(firstname_counts[['firstname', 'firstname_count', 'firstname_rate']], on='firstname', how='left')\n",
    "df_indian = df_indian.merge(lastname_counts[['lastname', 'lastname_count', 'lastname_rate']], on='lastname', how='left')\n",
    "df_indian'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_combined = pd.concat([df_us, df_indian], ignore_index=True)\\ndf_combined.to_csv(\"../output/USIN.csv\", index=False)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_combined = pd.concat([df_us, df_indian], ignore_index=True)\n",
    "df_combined.to_csv(\"../output/USIN.csv\", index=False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>name</th>\n",
       "      <th>indian</th>\n",
       "      <th>firstname_count</th>\n",
       "      <th>firstname_rate</th>\n",
       "      <th>lastname_count</th>\n",
       "      <th>lastname_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brandon</td>\n",
       "      <td>Sylvester</td>\n",
       "      <td>brandon sylvester</td>\n",
       "      <td>False</td>\n",
       "      <td>58421</td>\n",
       "      <td>0.189127</td>\n",
       "      <td>1272</td>\n",
       "      <td>0.004118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chris</td>\n",
       "      <td>Toussaint</td>\n",
       "      <td>chris toussaint</td>\n",
       "      <td>False</td>\n",
       "      <td>131039</td>\n",
       "      <td>0.424215</td>\n",
       "      <td>1691</td>\n",
       "      <td>0.005474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Willie</td>\n",
       "      <td>Gotti</td>\n",
       "      <td>willie gotti</td>\n",
       "      <td>False</td>\n",
       "      <td>10987</td>\n",
       "      <td>0.035568</td>\n",
       "      <td>693</td>\n",
       "      <td>0.002243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cristobal</td>\n",
       "      <td>Corona</td>\n",
       "      <td>cristobal corona</td>\n",
       "      <td>False</td>\n",
       "      <td>2640</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>9672</td>\n",
       "      <td>0.031311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wilmer</td>\n",
       "      <td>Diaz</td>\n",
       "      <td>wilmer diaz</td>\n",
       "      <td>False</td>\n",
       "      <td>4269</td>\n",
       "      <td>0.013820</td>\n",
       "      <td>91634</td>\n",
       "      <td>0.296648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36734983</th>\n",
       "      <td>Vikas</td>\n",
       "      <td>Chakchanpur</td>\n",
       "      <td>vikas chakchanpur</td>\n",
       "      <td>True</td>\n",
       "      <td>8871</td>\n",
       "      <td>0.151765</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36734984</th>\n",
       "      <td>Dipu</td>\n",
       "      <td>Gupta</td>\n",
       "      <td>dipu gupta</td>\n",
       "      <td>True</td>\n",
       "      <td>1526</td>\n",
       "      <td>0.026107</td>\n",
       "      <td>43396</td>\n",
       "      <td>0.742419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36734985</th>\n",
       "      <td>Riya</td>\n",
       "      <td>Naharwal</td>\n",
       "      <td>riya naharwal</td>\n",
       "      <td>True</td>\n",
       "      <td>6367</td>\n",
       "      <td>0.108927</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36734986</th>\n",
       "      <td>Jashandeep</td>\n",
       "      <td>Hanjra</td>\n",
       "      <td>jashandeep hanjra</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36734987</th>\n",
       "      <td>Jony</td>\n",
       "      <td>Bindas</td>\n",
       "      <td>jony bindas</td>\n",
       "      <td>True</td>\n",
       "      <td>305</td>\n",
       "      <td>0.005218</td>\n",
       "      <td>66</td>\n",
       "      <td>0.001129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36734988 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           firstname     lastname               name  indian  firstname_count  \\\n",
       "0            Brandon    Sylvester  brandon sylvester   False            58421   \n",
       "1              Chris    Toussaint    chris toussaint   False           131039   \n",
       "2             Willie        Gotti       willie gotti   False            10987   \n",
       "3          Cristobal       Corona   cristobal corona   False             2640   \n",
       "4             Wilmer         Diaz        wilmer diaz   False             4269   \n",
       "...              ...          ...                ...     ...              ...   \n",
       "36734983       Vikas  Chakchanpur  vikas chakchanpur    True             8871   \n",
       "36734984        Dipu        Gupta         dipu gupta    True             1526   \n",
       "36734985        Riya     Naharwal      riya naharwal    True             6367   \n",
       "36734986  Jashandeep       Hanjra  jashandeep hanjra    True               17   \n",
       "36734987        Jony       Bindas        jony bindas    True              305   \n",
       "\n",
       "          firstname_rate  lastname_count  lastname_rate  \n",
       "0               0.189127            1272       0.004118  \n",
       "1               0.424215            1691       0.005474  \n",
       "2               0.035568             693       0.002243  \n",
       "3               0.008547            9672       0.031311  \n",
       "4               0.013820           91634       0.296648  \n",
       "...                  ...             ...            ...  \n",
       "36734983        0.151765               1       0.000017  \n",
       "36734984        0.026107           43396       0.742419  \n",
       "36734985        0.108927               8       0.000137  \n",
       "36734986        0.000291              43       0.000736  \n",
       "36734987        0.005218              66       0.001129  \n",
       "\n",
       "[36734988 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../output/USIN.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_features(train_data_label, output_file_path=\"USIN_features.csv\"):\n",
    "    # --------------------\n",
    "    # Load Data\n",
    "    # --------------------\n",
    "    \n",
    "    path = f\"../output/yearly/donors_{train_data_label}_pred_lastname.csv\"\n",
    "    train_data = pd.read_csv(path)\n",
    "        \n",
    "    train_data['id'] = range(1, len(train_data) + 1)\n",
    "    \n",
    "    # Clean data\n",
    "    train_data['firstname'] = train_data['firstname'].apply(lambda x: str(x).split(\" \")[0])\n",
    "    train_data = train_data.dropna(subset=['firstname', 'lastname', 'indian'])\n",
    "    \n",
    "    # --------------------\n",
    "    # Cutpoints\n",
    "    # --------------------\n",
    "    \n",
    "    c = 1\n",
    "    cutl = 10\n",
    "    \n",
    "    # --------------------\n",
    "    # Feature Creation\n",
    "    # --------------------\n",
    "    \n",
    "    # 1. First four letters of the first/last name:\n",
    "    train_data['first_name_f4'] = train_data['firstname'].str[:4]\n",
    "    train_data['last_name_f4'] = train_data['lastname'].str[:4]\n",
    "    \n",
    "    # First Names - Indian probability\n",
    "    indian_count_fn = train_data[train_data['indian'] == True].groupby('first_name_f4').size()\n",
    "    indian_count_fn.name = 'pop_indian_f4'\n",
    "    train_data = train_data.merge(indian_count_fn, how='left', on='first_name_f4')\n",
    "    \n",
    "    mean_pop = train_data.groupby('first_name_f4')['pop_indian_f4'].transform('mean')\n",
    "    count = train_data.groupby('first_name_f4')['pop_indian_f4'].transform('count')\n",
    "    train_data['pop_fn_indian_f4'] = mean_pop / (count + c)\n",
    "    \n",
    "    # Last Names - Indian probability\n",
    "    indian_count_ln = train_data[train_data['indian'] == True].groupby('last_name_f4').size()\n",
    "    indian_count_ln.name = 'pop_indian_f4_ln'\n",
    "    train_data = train_data.merge(indian_count_ln, how='left', on='last_name_f4')\n",
    "    \n",
    "    mean_pop = train_data.groupby('last_name_f4')['pop_indian_f4_ln'].transform('mean')\n",
    "    count = train_data.groupby('last_name_f4')['pop_indian_f4_ln'].transform('count')\n",
    "    train_data['pop_ln_indian_f4'] = mean_pop / count\n",
    "    \n",
    "    train_data = train_data.drop(columns=['pop_indian_f4', 'pop_indian_f4_ln'])\n",
    "    train_data = train_data.fillna(0)\n",
    "    \n",
    "    # 2. Last four letters of the first/last name:\n",
    "    train_data['first_name_l4'] = train_data['firstname'].str[-4:]\n",
    "    train_data['last_name_l4'] = train_data['lastname'].str[-4:]\n",
    "    \n",
    "    # First Names - Indian probability\n",
    "    indian_count_fn = train_data[train_data['indian'] == True].groupby('first_name_l4').size()\n",
    "    indian_count_fn.name = 'pop_indian_l4'\n",
    "    train_data = train_data.merge(indian_count_fn, how='left', on='first_name_l4')\n",
    "    \n",
    "    mean_pop = train_data.groupby('first_name_l4')['pop_indian_l4'].transform('mean')\n",
    "    count = train_data.groupby('first_name_l4')['pop_indian_l4'].transform('count')\n",
    "    train_data['pop_fn_indian_l4'] = mean_pop / (count + c)\n",
    "    \n",
    "    # Last Names - Indian probability\n",
    "    indian_count_ln = train_data[train_data['indian'] == True].groupby('last_name_l4').size()\n",
    "    indian_count_ln.name = 'pop_indian_l4_ln'\n",
    "    train_data = train_data.merge(indian_count_ln, how='left', on='last_name_l4')\n",
    "    \n",
    "    mean_pop = train_data.groupby('last_name_l4')['pop_indian_l4_ln'].transform('mean')\n",
    "    count = train_data.groupby('last_name_l4')['pop_indian_l4_ln'].transform('count')\n",
    "    train_data['pop_ln_indian_l4'] = mean_pop / (count + c)\n",
    "    \n",
    "    train_data = train_data.drop(columns=['pop_indian_l4', 'pop_indian_l4_ln'])\n",
    "    train_data = train_data.fillna(0)\n",
    "    \n",
    "    # 3. Full first/last name:\n",
    "    # First Names - Indian probability\n",
    "    indian_count_fn = train_data[train_data['indian'] == True].groupby('firstname').size()\n",
    "    indian_count_fn.name = 'pop_indian_fn'\n",
    "    train_data = train_data.merge(indian_count_fn, how='left', on='firstname')\n",
    "    \n",
    "    mean_pop = train_data.groupby('firstname')['pop_indian_fn'].transform('mean')\n",
    "    count = train_data.groupby('firstname')['pop_indian_fn'].transform('count')\n",
    "    train_data['pop_fn_indian'] = mean_pop / (count + c)\n",
    "    \n",
    "    # Last Names - Indian probability\n",
    "    indian_count_ln = train_data[train_data['indian'] == True].groupby('lastname').size()\n",
    "    indian_count_ln.name = 'pop_indian_ln'\n",
    "    train_data = train_data.merge(indian_count_ln, how='left', on='lastname')\n",
    "    \n",
    "    mean_pop = train_data.groupby('lastname')['pop_indian_ln'].transform('mean')\n",
    "    count = train_data.groupby('lastname')['pop_indian_ln'].transform('count')\n",
    "    train_data['pop_ln_indian'] = mean_pop / (count + c)\n",
    "    \n",
    "    train_data = train_data.drop(columns=['pop_indian_fn', 'pop_indian_ln'])\n",
    "    train_data = train_data.fillna(0)\n",
    "    \n",
    "    # Indicator Low Frequency of Name:\n",
    "    train_data['first_name_low'] = (train_data.groupby('firstname')['firstname'].transform('count') < cutl).astype(int)\n",
    "    train_data['last_name_low'] = (train_data.groupby('lastname')['lastname'].transform('count') < cutl).astype(int)\n",
    "    \n",
    "    # Best Evidence\n",
    "    train_data['best_evidence_indian'] = train_data[['pop_ln_indian', 'pop_fn_indian']].max(axis=1)\n",
    "    \n",
    "    # Select final columns\n",
    "    final_columns = [\n",
    "        'id', 'firstname', 'lastname', 'indian', \n",
    "        'first_name_f4', 'first_name_l4',\n",
    "        'last_name_f4', 'last_name_l4',\n",
    "        'pop_ln_indian', 'pop_fn_indian',\n",
    "        'best_evidence_indian',\n",
    "        'pop_ln_indian_f4', 'pop_fn_indian_f4',\n",
    "        'pop_ln_indian_l4', 'pop_fn_indian_l4',\n",
    "        'last_name_low', 'first_name_low'\n",
    "    ]\n",
    "    \n",
    "    train_data = train_data[final_columns]\n",
    "    \n",
    "    # Save output\n",
    "    output_file_path = f\"../data/donors{train_data_label}_{output_file_path}\"\n",
    "    train_data.to_csv(output_file_path, index=False)\n",
    "    \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>indian</th>\n",
       "      <th>first_name_f4</th>\n",
       "      <th>first_name_l4</th>\n",
       "      <th>last_name_f4</th>\n",
       "      <th>last_name_l4</th>\n",
       "      <th>pop_ln_indian</th>\n",
       "      <th>pop_fn_indian</th>\n",
       "      <th>best_evidence_indian</th>\n",
       "      <th>pop_ln_indian_f4</th>\n",
       "      <th>pop_fn_indian_f4</th>\n",
       "      <th>pop_ln_indian_l4</th>\n",
       "      <th>pop_fn_indian_l4</th>\n",
       "      <th>last_name_low</th>\n",
       "      <th>first_name_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>actblue</td>\n",
       "      <td>actblue</td>\n",
       "      <td>False</td>\n",
       "      <td>actb</td>\n",
       "      <td>blue</td>\n",
       "      <td>actb</td>\n",
       "      <td>blue</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>michael</td>\n",
       "      <td>bloomberg</td>\n",
       "      <td>False</td>\n",
       "      <td>mich</td>\n",
       "      <td>hael</td>\n",
       "      <td>bloo</td>\n",
       "      <td>berg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>tom</td>\n",
       "      <td>steyer</td>\n",
       "      <td>False</td>\n",
       "      <td>tom</td>\n",
       "      <td>tom</td>\n",
       "      <td>stey</td>\n",
       "      <td>eyer</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>timothy</td>\n",
       "      <td>mellon</td>\n",
       "      <td>False</td>\n",
       "      <td>timo</td>\n",
       "      <td>othy</td>\n",
       "      <td>mell</td>\n",
       "      <td>llon</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.005252</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.044110</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>miriam</td>\n",
       "      <td>adelson</td>\n",
       "      <td>False</td>\n",
       "      <td>miri</td>\n",
       "      <td>riam</td>\n",
       "      <td>adel</td>\n",
       "      <td>lson</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588744</th>\n",
       "      <td>3588932</td>\n",
       "      <td>elizabeth</td>\n",
       "      <td>english</td>\n",
       "      <td>False</td>\n",
       "      <td>eliz</td>\n",
       "      <td>beth</td>\n",
       "      <td>engl</td>\n",
       "      <td>lish</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.002251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588745</th>\n",
       "      <td>3588933</td>\n",
       "      <td>linda</td>\n",
       "      <td>rapp</td>\n",
       "      <td>False</td>\n",
       "      <td>lind</td>\n",
       "      <td>inda</td>\n",
       "      <td>rapp</td>\n",
       "      <td>rapp</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588746</th>\n",
       "      <td>3588934</td>\n",
       "      <td>julie</td>\n",
       "      <td>oldham</td>\n",
       "      <td>False</td>\n",
       "      <td>juli</td>\n",
       "      <td>ulie</td>\n",
       "      <td>oldh</td>\n",
       "      <td>dham</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.009736</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588747</th>\n",
       "      <td>3588935</td>\n",
       "      <td>nancy</td>\n",
       "      <td>martin</td>\n",
       "      <td>False</td>\n",
       "      <td>nanc</td>\n",
       "      <td>ancy</td>\n",
       "      <td>mart</td>\n",
       "      <td>rtin</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588748</th>\n",
       "      <td>3588936</td>\n",
       "      <td>sue</td>\n",
       "      <td>corradetti</td>\n",
       "      <td>False</td>\n",
       "      <td>sue</td>\n",
       "      <td>sue</td>\n",
       "      <td>corr</td>\n",
       "      <td>etti</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3588749 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  firstname    lastname  indian first_name_f4 first_name_l4  \\\n",
       "0              1    actblue     actblue   False          actb          blue   \n",
       "1              2    michael   bloomberg   False          mich          hael   \n",
       "2              3        tom      steyer   False           tom           tom   \n",
       "3              4    timothy      mellon   False          timo          othy   \n",
       "4              5     miriam     adelson   False          miri          riam   \n",
       "...          ...        ...         ...     ...           ...           ...   \n",
       "3588744  3588932  elizabeth     english   False          eliz          beth   \n",
       "3588745  3588933      linda        rapp   False          lind          inda   \n",
       "3588746  3588934      julie      oldham   False          juli          ulie   \n",
       "3588747  3588935      nancy      martin   False          nanc          ancy   \n",
       "3588748  3588936        sue  corradetti   False           sue           sue   \n",
       "\n",
       "        last_name_f4 last_name_l4  pop_ln_indian  pop_fn_indian  \\\n",
       "0               actb         blue       0.000000       0.000000   \n",
       "1               bloo         berg       0.000000       0.001818   \n",
       "2               stey         eyer       0.000000       0.000903   \n",
       "3               mell         llon       0.000000       0.001856   \n",
       "4               adel         lson       0.000000       0.000805   \n",
       "...              ...          ...            ...            ...   \n",
       "3588744         engl         lish       0.001623       0.002059   \n",
       "3588745         rapp         rapp       0.000000       0.001796   \n",
       "3588746         oldh         dham       0.000000       0.001888   \n",
       "3588747         mart         rtin       0.000873       0.001560   \n",
       "3588748         corr         etti       0.000000       0.001309   \n",
       "\n",
       "         best_evidence_indian  pop_ln_indian_f4  pop_fn_indian_f4  \\\n",
       "0                    0.000000          0.000000          0.000000   \n",
       "1                    0.001818          0.000000          0.001930   \n",
       "2                    0.000903          0.000000          0.000903   \n",
       "3                    0.001856          0.005252          0.001843   \n",
       "4                    0.000805          0.002618          0.000775   \n",
       "...                       ...               ...               ...   \n",
       "3588744              0.002059          0.001106          0.002022   \n",
       "3588745              0.001796          0.000000          0.001779   \n",
       "3588746              0.001888          0.000000          0.002424   \n",
       "3588747              0.001560          0.000792          0.001580   \n",
       "3588748              0.001309          0.000000          0.001309   \n",
       "\n",
       "         pop_ln_indian_l4  pop_fn_indian_l4  last_name_low  first_name_low  \n",
       "0                0.000000          0.000000              1               1  \n",
       "1                0.000404          0.001825              0               0  \n",
       "2                0.000175          0.000903              0               0  \n",
       "3                0.044110          0.002094              0               0  \n",
       "4                0.000659          0.003446              0               0  \n",
       "...                   ...               ...            ...             ...  \n",
       "3588744          0.002060          0.002251              0               0  \n",
       "3588745          0.000000          0.002167              0               0  \n",
       "3588746          0.009736          0.001882              0               0  \n",
       "3588747          0.000780          0.001601              0               0  \n",
       "3588748          0.007962          0.001309              1               0  \n",
       "\n",
       "[3588749 rows x 17 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create_train_features(str(year))\n",
    "output_path = f\"../data/donors{year}_USIN_features.csv\"\n",
    "features = pd.read_csv(output_path)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_set_indian(features, num_rows=100000, full_data=False):\n",
    "\n",
    "    features = features.dropna(subset=['firstname', 'lastname', 'indian'])\n",
    "    features.fillna(0, inplace=True)\n",
    "    \n",
    "    if not full_data:\n",
    "        features = features.sample(n=num_rows, random_state=42)\n",
    "    \n",
    "    features.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    first_name_encoder = LabelEncoder()\n",
    "    X_first_name = first_name_encoder.fit_transform(features['firstname'].fillna('unknown'))\n",
    "    \n",
    "    last_name_encoder = LabelEncoder()\n",
    "    X_last_name = last_name_encoder.fit_transform(features['lastname'].fillna('unknown'))\n",
    "    \n",
    "    for col in ['first_name_f4', 'last_name_f4', 'first_name_l4', 'last_name_l4']:\n",
    "        if col in features.columns:\n",
    "            features[col] = features[col].astype(str)\n",
    "    \n",
    "    first_name_f4_encoder = LabelEncoder()\n",
    "    X_first_name_f4 = first_name_f4_encoder.fit_transform(features['first_name_f4'].fillna('unknown'))\n",
    "    \n",
    "    last_name_f4_encoder = LabelEncoder()\n",
    "    X_last_name_f4 = last_name_f4_encoder.fit_transform(features['last_name_f4'].fillna('unknown'))    \n",
    "    \n",
    "    first_name_l4_encoder = LabelEncoder()\n",
    "    X_first_name_l4 = first_name_l4_encoder.fit_transform(features['first_name_l4'].fillna('unknown'))\n",
    "    \n",
    "    last_name_l4_encoder = LabelEncoder()\n",
    "    X_last_name_l4 = last_name_l4_encoder.fit_transform(features['last_name_l4'].fillna('unknown'))\n",
    "    \n",
    "    # Add encoded names as features\n",
    "    features['first_name_encoded'] = X_first_name\n",
    "    features['last_name_encoded'] = X_last_name\n",
    "    features['first_name_f4_encoded'] = X_first_name_f4\n",
    "    features['last_name_f4_encoded'] = X_last_name_f4\n",
    "    features['first_name_l4_encoded'] = X_first_name_l4\n",
    "    features['last_name_l4_encoded'] = X_last_name_l4\n",
    "    \n",
    "    # Keep relevant columns\n",
    "    main_features = features[['firstname', 'lastname', 'indian', 'id', \n",
    "                             'first_name_encoded', 'last_name_encoded',\n",
    "                             'first_name_f4_encoded', 'last_name_f4_encoded',\n",
    "                             'first_name_l4_encoded', 'last_name_l4_encoded']]\n",
    "    y = main_features['indian'].astype(int)\n",
    "    X = main_features.drop(['id', 'firstname', 'lastname', 'indian'], axis=1, errors='ignore')\n",
    "    \n",
    "    print(f\"X shape = {X.shape}, y shape = {y.shape}\")\n",
    "    print(f\"Indian count: {y.sum()}, Non-Indian count: {len(y) - y.sum()}\")\n",
    "    \n",
    "    return X, y, main_features, (first_name_encoder, last_name_encoder,\n",
    "            first_name_f4_encoder, last_name_f4_encoder,\n",
    "            first_name_l4_encoder, last_name_l4_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape = (3587209, 6), y shape = (3587209,)\n",
      "Indian count: 43220, Non-Indian count: 3543989\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name_encoded</th>\n",
       "      <th>last_name_encoded</th>\n",
       "      <th>first_name_f4_encoded</th>\n",
       "      <th>last_name_f4_encoded</th>\n",
       "      <th>first_name_l4_encoded</th>\n",
       "      <th>last_name_l4_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656</td>\n",
       "      <td>2160</td>\n",
       "      <td>293</td>\n",
       "      <td>458</td>\n",
       "      <td>3309</td>\n",
       "      <td>5876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59248</td>\n",
       "      <td>39073</td>\n",
       "      <td>15668</td>\n",
       "      <td>4795</td>\n",
       "      <td>8431</td>\n",
       "      <td>5513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88498</td>\n",
       "      <td>383238</td>\n",
       "      <td>23738</td>\n",
       "      <td>41539</td>\n",
       "      <td>22257</td>\n",
       "      <td>12950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88136</td>\n",
       "      <td>262404</td>\n",
       "      <td>23571</td>\n",
       "      <td>28035</td>\n",
       "      <td>17730</td>\n",
       "      <td>24136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60162</td>\n",
       "      <td>2597</td>\n",
       "      <td>15816</td>\n",
       "      <td>517</td>\n",
       "      <td>19288</td>\n",
       "      <td>24723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587204</th>\n",
       "      <td>24747</td>\n",
       "      <td>115509</td>\n",
       "      <td>6401</td>\n",
       "      <td>12261</td>\n",
       "      <td>3136</td>\n",
       "      <td>23878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587205</th>\n",
       "      <td>51619</td>\n",
       "      <td>325882</td>\n",
       "      <td>14257</td>\n",
       "      <td>36826</td>\n",
       "      <td>10475</td>\n",
       "      <td>34283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587206</th>\n",
       "      <td>42924</td>\n",
       "      <td>292638</td>\n",
       "      <td>12054</td>\n",
       "      <td>32622</td>\n",
       "      <td>23221</td>\n",
       "      <td>8656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587207</th>\n",
       "      <td>62628</td>\n",
       "      <td>251703</td>\n",
       "      <td>16614</td>\n",
       "      <td>27425</td>\n",
       "      <td>1653</td>\n",
       "      <td>36515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587208</th>\n",
       "      <td>83699</td>\n",
       "      <td>77937</td>\n",
       "      <td>22461</td>\n",
       "      <td>7409</td>\n",
       "      <td>21444</td>\n",
       "      <td>12611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3587209 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         first_name_encoded  last_name_encoded  first_name_f4_encoded  \\\n",
       "0                       656               2160                    293   \n",
       "1                     59248              39073                  15668   \n",
       "2                     88498             383238                  23738   \n",
       "3                     88136             262404                  23571   \n",
       "4                     60162               2597                  15816   \n",
       "...                     ...                ...                    ...   \n",
       "3587204               24747             115509                   6401   \n",
       "3587205               51619             325882                  14257   \n",
       "3587206               42924             292638                  12054   \n",
       "3587207               62628             251703                  16614   \n",
       "3587208               83699              77937                  22461   \n",
       "\n",
       "         last_name_f4_encoded  first_name_l4_encoded  last_name_l4_encoded  \n",
       "0                         458                   3309                  5876  \n",
       "1                        4795                   8431                  5513  \n",
       "2                       41539                  22257                 12950  \n",
       "3                       28035                  17730                 24136  \n",
       "4                         517                  19288                 24723  \n",
       "...                       ...                    ...                   ...  \n",
       "3587204                 12261                   3136                 23878  \n",
       "3587205                 36826                  10475                 34283  \n",
       "3587206                 32622                  23221                  8656  \n",
       "3587207                 27425                   1653                 36515  \n",
       "3587208                  7409                  21444                 12611  \n",
       "\n",
       "[3587209 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, main_features, encoders = process_data_set_indian(features, num_rows=1, full_data=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_indian_classifier(train_data_label, X_train, y_train, encoders, epochs=5):\n",
    "    print(\"date and time =\", datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "\n",
    "    best_loss = 999999999\n",
    "    patience = 1\n",
    "    patience_counter = 0\n",
    "    early_stop = False\n",
    "    batch_size = 1024\n",
    "    \n",
    "    vocab_sizes = [len(encoder.classes_) for encoder in encoders]\n",
    "    print(f\"First name vocabulary size: {vocab_sizes[0]}\")\n",
    "    print(f\"Last name vocabulary size: {vocab_sizes[1]}\")\n",
    "    \n",
    "    X_numeric = X_train.values.astype(np.float32)\n",
    "    print(f\"Using {X_numeric.shape[1]} numeric features + character embeddings\")\n",
    "    \n",
    "    X_numeric_tensor = torch.tensor(X_numeric, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y_train.values.astype(np.float32), dtype=torch.float32)\n",
    "    \n",
    "    encoded_indices = {}\n",
    "    for col in ['first_name_encoded', 'last_name_encoded', \n",
    "                'first_name_f4_encoded', 'last_name_f4_encoded',\n",
    "                'first_name_l4_encoded', 'last_name_l4_encoded']:\n",
    "        encoded_indices[col] = X_train.columns.get_loc(col)\n",
    "    \n",
    "    dataset = TensorDataset(X_numeric_tensor, y_tensor)\n",
    "    train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    numeric_dim = X_numeric.shape[1] - len(encoded_indices)\n",
    "    embedding_dim = 32\n",
    "    hidden_dim = 128\n",
    "    \n",
    "    embedding_layers = {\n",
    "        'first_name': nn.Embedding(vocab_sizes[0] + 10, embedding_dim),\n",
    "        'last_name': nn.Embedding(vocab_sizes[1] + 10, embedding_dim),\n",
    "        'first_name_f4': nn.Embedding(vocab_sizes[2] + 10, embedding_dim // 2),\n",
    "        'last_name_f4': nn.Embedding(vocab_sizes[3] + 10, embedding_dim // 2),\n",
    "        'first_name_l4': nn.Embedding(vocab_sizes[4] + 10, embedding_dim // 2),\n",
    "        'last_name_l4': nn.Embedding(vocab_sizes[5] + 10, embedding_dim // 2)\n",
    "    }\n",
    "    \n",
    "    total_embedding_dim = (2 * embedding_dim) + (4 * (embedding_dim // 2))  # 2 full + 4 partial\n",
    "    linear1 = nn.Linear(numeric_dim + total_embedding_dim, hidden_dim)\n",
    "    linear2 = nn.Linear(hidden_dim, 1)\n",
    "    relu = nn.ReLU()\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    parameters = []\n",
    "    for layer in embedding_layers.values():\n",
    "        parameters.extend(layer.parameters())\n",
    "    parameters.extend(linear1.parameters())\n",
    "    parameters.extend(linear2.parameters())\n",
    "    \n",
    "    print(\"date and time =\", datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "    \n",
    "    indian_count = y_train.sum()\n",
    "    non_indian_count = len(y_train) - indian_count\n",
    "    weight_for_indian = non_indian_count / indian_count * 2.0  # 2x weight for recall focus\n",
    "    weight_for_non_indian = 1.0\n",
    "    class_weights = torch.tensor([weight_for_non_indian, weight_for_indian], dtype=torch.float32)\n",
    "    print(f\"Class weights - Non-Indian: {weight_for_non_indian}, Indian: {weight_for_indian:.2f}\")\n",
    "    \n",
    "    criterion = torch.nn.BCELoss(weight=class_weights[1])\n",
    "    optimizer = torch.optim.Adam(parameters, lr=0.001)\n",
    "\n",
    "    iteration_list = []\n",
    "    loss_list = []\n",
    "    accuracy_list = []\n",
    "    average_loss = 0\n",
    "    iteration = 0\n",
    "\n",
    "    for epoch in range(int(epochs)):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (features_batch, labels) in enumerate(train_loader):\n",
    "            iteration = iteration + 1\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Split the batch into numeric features and encoded names\n",
    "            numeric_features = features_batch[:, [idx for idx in range(features_batch.shape[1]) \n",
    "                                                if idx not in encoded_indices.values()]]\n",
    "            \n",
    "            # Get all embedded features\n",
    "            embedded_features = []\n",
    "            for col_name, idx in encoded_indices.items():\n",
    "                name_type = col_name.split('_encoded')[0]\n",
    "                ids = features_batch[:, idx].long()\n",
    "                emb = embedding_layers[name_type](ids)\n",
    "                embedded_features.append(emb)\n",
    "            \n",
    "            # Combine all features\n",
    "            combined = torch.cat([numeric_features] + embedded_features, dim=1)\n",
    "            hidden = relu(linear1(combined))\n",
    "            outputs = sigmoid(linear2(hidden))\n",
    "            \n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.squeeze() == labels).sum().item()\n",
    "            average_loss += loss.item()\n",
    "            \n",
    "            if iteration % 1024 == 0:\n",
    "                current_loss = average_loss / 1024 if average_loss > 0 else loss.item()\n",
    "                \n",
    "                # Check if loss improved\n",
    "                if current_loss < best_loss:\n",
    "                    best_loss = current_loss\n",
    "                    patience_counter = 0\n",
    "                    torch.save({\n",
    "                        'embedding_layers': {name: layer.state_dict() for name, layer in embedding_layers.items()},\n",
    "                        'linear1': linear1.state_dict(),\n",
    "                        'linear2': linear2.state_dict(),\n",
    "                        'encoder_classes': {\n",
    "                            'first_name': encoders[0].classes_,\n",
    "                            'last_name': encoders[1].classes_,\n",
    "                            'first_name_f4': encoders[2].classes_,\n",
    "                            'last_name_f4': encoders[3].classes_,\n",
    "                            'first_name_l4': encoders[4].classes_,\n",
    "                            'last_name_l4': encoders[5].classes_\n",
    "                        },\n",
    "                        'encoded_indices': encoded_indices,\n",
    "                        'feature_columns': list(X_train.columns)\n",
    "                    }, f\"./models/ethnicia_classifier_{train_data_label}_best.pt\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    print(f\"No improvement for {patience_counter}/{patience} iterations\")\n",
    "                    \n",
    "                # Check for early stopping\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"Early stopping triggered at iteration {iteration}\")\n",
    "                    early_stop = True\n",
    "                    break\n",
    "\n",
    "            # Add this at the end of the epoch loop\n",
    "            if early_stop:\n",
    "                break\n",
    "\n",
    "            if iteration % 1024 == 0:\n",
    "                iteration_list.append(iteration)\n",
    "                loss_list.append(average_loss / 1024)\n",
    "                accuracy = 100 * correct / total\n",
    "                print(\"Iteration: {}. Loss: {}. Accuracy: {}.\".format(iteration, average_loss / 1024, accuracy))\n",
    "                accuracy_list.append(accuracy)\n",
    "                total = 0\n",
    "                correct = 0\n",
    "                average_loss = 0\n",
    "\n",
    "    path = f\"./models/ethnicia_classifier_{train_data_label}.pt\"\n",
    "    torch.save({\n",
    "        'embedding_layers': {name: layer.state_dict() for name, layer in embedding_layers.items()},\n",
    "        'linear1': linear1.state_dict(),\n",
    "        'linear2': linear2.state_dict(),\n",
    "        'encoder_classes': {\n",
    "            'first_name': encoders[0].classes_,\n",
    "            'last_name': encoders[1].classes_,\n",
    "            'first_name_f4': encoders[2].classes_,\n",
    "            'last_name_f4': encoders[3].classes_,\n",
    "            'first_name_l4': encoders[4].classes_,\n",
    "            'last_name_l4': encoders[5].classes_\n",
    "        },\n",
    "        'encoded_indices': encoded_indices,\n",
    "        'feature_columns': list(X_train.columns)\n",
    "    }, path)\n",
    "\n",
    "    plt.plot(iteration_list, loss_list)\n",
    "    plt.xlabel('Number of Iterations')\n",
    "    plt.ylabel('Loss on Training Set')\n",
    "    plt.title('Indian Classifier - EthnicIA')\n",
    "    plt.savefig(f\"../images/ethnicia2_{train_data_label}_loss.png\")\n",
    "    plt.clf()\n",
    "\n",
    "    plt.plot(iteration_list, accuracy_list)\n",
    "    plt.xlabel('Number of Iterations')\n",
    "    plt.ylabel('Accuracy on Training Set')\n",
    "    plt.title('Indian Classifier - EthnicIA')\n",
    "    plt.savefig(f\"../images/ethnicia2_{train_data_label}_accuracy.png\")\n",
    "    plt.clf()\n",
    "    \n",
    "    print(\"date and time =\", datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "    print(f\"Training completed. Model saved as: ethnicia_classifier_{train_data_label}.pt\")\n",
    "    \n",
    "    return {\n",
    "        'embedding_layers': embedding_layers,\n",
    "        'linear1': linear1,\n",
    "        'linear2': linear2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_indian_classifier(model_dict, X_test, y_test, encoders):\n",
    "    \n",
    "    X_numeric_tensor = torch.tensor(X_test.values.astype(np.float32), dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y_test.values.astype(np.float32), dtype=torch.float32)\n",
    "    \n",
    "    # Get the indices of encoded name columns from the saved model info\n",
    "    encoded_indices = {}\n",
    "    for col in ['first_name_encoded', 'last_name_encoded', \n",
    "                'first_name_f4_encoded', 'last_name_f4_encoded',\n",
    "                'first_name_l4_encoded', 'last_name_l4_encoded']:\n",
    "        encoded_indices[col] = X_test.columns.get_loc(col)\n",
    "    \n",
    "    # Set model to eval mode\n",
    "    embedding_layers = model_dict['embedding_layers']\n",
    "    linear1 = model_dict['linear1']\n",
    "    linear2 = model_dict['linear2']\n",
    "    \n",
    "    # Set all components to evaluation mode\n",
    "    for layer in embedding_layers.values():\n",
    "        layer.eval()\n",
    "    linear1.eval()\n",
    "    linear2.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Extract numeric features (excluding all encoded columns)\n",
    "        numeric_features = X_numeric_tensor[:, [idx for idx in range(X_numeric_tensor.shape[1]) \n",
    "                                            if idx not in encoded_indices.values()]]\n",
    "        \n",
    "        # Extract all encoded name IDs\n",
    "        first_name_ids = X_numeric_tensor[:, encoded_indices['first_name_encoded']].long()\n",
    "        last_name_ids = X_numeric_tensor[:, encoded_indices['last_name_encoded']].long()\n",
    "        first_name_f4_ids = X_numeric_tensor[:, encoded_indices['first_name_f4_encoded']].long()\n",
    "        last_name_f4_ids = X_numeric_tensor[:, encoded_indices['last_name_f4_encoded']].long()\n",
    "        first_name_l4_ids = X_numeric_tensor[:, encoded_indices['first_name_l4_encoded']].long()\n",
    "        last_name_l4_ids = X_numeric_tensor[:, encoded_indices['last_name_l4_encoded']].long()\n",
    "        \n",
    "        # Forward pass with all embeddings\n",
    "        first_name_emb = embedding_layers['first_name'](first_name_ids)\n",
    "        last_name_emb = embedding_layers['last_name'](last_name_ids)\n",
    "        first_name_f4_emb = embedding_layers['first_name_f4'](first_name_f4_ids)\n",
    "        last_name_f4_emb = embedding_layers['last_name_f4'](last_name_f4_ids)\n",
    "        first_name_l4_emb = embedding_layers['first_name_l4'](first_name_l4_ids)\n",
    "        last_name_l4_emb = embedding_layers['last_name_l4'](last_name_l4_ids)\n",
    "        \n",
    "        # Combine all features\n",
    "        combined = torch.cat([\n",
    "            numeric_features, \n",
    "            first_name_emb, \n",
    "            last_name_emb,\n",
    "            first_name_f4_emb,\n",
    "            last_name_f4_emb,\n",
    "            first_name_l4_emb,\n",
    "            last_name_l4_emb\n",
    "        ], dim=1)\n",
    "        \n",
    "        hidden = torch.relu(model_dict['linear1'](combined))\n",
    "        outputs = torch.sigmoid(model_dict['linear2'](hidden))\n",
    "        \n",
    "        predictions = (outputs > 0.5).float()\n",
    "        correct = (predictions.squeeze() == y_tensor).sum().item()\n",
    "        total = y_tensor.size(0)\n",
    "        accuracy = 100 * correct / total\n",
    "        \n",
    "        true_positives = ((predictions.squeeze() == 1) & (y_tensor == 1)).sum().item()\n",
    "        false_positives = ((predictions.squeeze() == 1) & (y_tensor == 0)).sum().item()\n",
    "        true_negatives = ((predictions.squeeze() == 0) & (y_tensor == 0)).sum().item()\n",
    "        false_negatives = ((predictions.squeeze() == 0) & (y_tensor == 1)).sum().item()\n",
    "        \n",
    "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "        test_metrics = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1_score,\n",
    "            'true_positives': true_positives,\n",
    "            'false_positives': false_positives,\n",
    "            'true_negatives': true_negatives,\n",
    "            'false_negatives': false_negatives,\n",
    "            'total_samples': total\n",
    "        }\n",
    "    \n",
    "    return test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_indian_classifier(train_data_label, X, y, test_size=0.3, epochs=50):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    model_dict = train_indian_classifier(train_data_label, X_train, y_train, encoders, epochs=epochs)\n",
    "    \n",
    "    print(\"\\nTesting model...\")\n",
    "    test_metrics = test_indian_classifier(model_dict, X_test, y_test, encoders)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TEST RESULTS:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Accuracy: {test_metrics['accuracy']:.2f}%\")\n",
    "    print(f\"Precision: {test_metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {test_metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {test_metrics['f1_score']:.4f}\")\n",
    "    print(f\"True Positives: {test_metrics['true_positives']}\")\n",
    "    print(f\"False Positives: {test_metrics['false_positives']}\")\n",
    "    print(f\"True Negatives: {test_metrics['true_negatives']}\")\n",
    "    print(f\"False Negatives: {test_metrics['false_negatives']}\")\n",
    "    \n",
    "    return model_dict, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "date and time = 25/08/2025 22:20:04\n",
      "First name vocabulary size: 98623\n",
      "Last name vocabulary size: 450582\n",
      "Using 6 numeric features + character embeddings\n",
      "date and time = 25/08/2025 22:20:04\n",
      "Class weights - Non-Indian: 1.0, Indian: 164.00\n",
      "Iteration: 1024. Loss: 9.80058817495592. Accuracy: 98.72274398803711.\n",
      "Iteration: 2048. Loss: 4.6134914754657075. Accuracy: 99.224853515625.\n",
      "Iteration: 3072. Loss: 3.3604008321417496. Accuracy: 99.44593093699515.\n",
      "Iteration: 4096. Loss: 2.7569176166434772. Accuracy: 99.49626922607422.\n",
      "Iteration: 5120. Loss: 2.393413809069898. Accuracy: 99.64314398364486.\n",
      "Iteration: 6144. Loss: 1.9421039787121117. Accuracy: 99.63226318359375.\n",
      "Iteration: 7168. Loss: 1.8154856824548915. Accuracy: 99.64094161987305.\n",
      "Iteration: 8192. Loss: 1.4263477823405992. Accuracy: 99.73376069177671.\n",
      "Iteration: 9216. Loss: 1.388573322125012. Accuracy: 99.72286224365234.\n",
      "Iteration: 10240. Loss: 1.1860605213369126. Accuracy: 99.80354665595794.\n",
      "Iteration: 11264. Loss: 0.9825448643387062. Accuracy: 99.7995376586914.\n",
      "No improvement for 1/1 iterations\n",
      "Early stopping triggered at iteration 12288\n",
      "date and time = 25/08/2025 22:31:59\n",
      "Training completed. Model saved as: ethnicia_classifier_20.pt\n",
      "\n",
      "Testing model...\n",
      "\n",
      "==================================================\n",
      "TEST RESULTS:\n",
      "==================================================\n",
      "Accuracy: 99.57%\n",
      "Precision: 0.8340\n",
      "Recall: 0.8005\n",
      "F1 Score: 0.8169\n",
      "True Positives: 10379\n",
      "False Positives: 2066\n",
      "True Negatives: 1061131\n",
      "False Negatives: 2587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, metrics = train_and_test_indian_classifier(str(year), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tp = metrics['true_positives']\n",
    "fp = metrics['false_positives']\n",
    "tn = metrics['true_negatives']\n",
    "fn = metrics['false_negatives']\n",
    "cm = np.array([[tn, fp], [fn, tp]])\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                                display_labels=['Non-Indian', 'Indian'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp.plot(cmap='Blues', ax=ax, values_format='d')\n",
    "ax.set_title(\"EthnicIA Classifier Results\", fontsize=14, pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    \n",
    "    checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    \n",
    "    # Recreate model architecture\n",
    "    embedding_dim = 32\n",
    "    vocab_sizes = {\n",
    "        'first_name': len(checkpoint['encoder_classes']['first_name']) + 10,\n",
    "        'last_name': len(checkpoint['encoder_classes']['last_name']) + 10,\n",
    "        'first_name_f4': len(checkpoint['encoder_classes']['first_name_f4']) + 10,\n",
    "        'last_name_f4': len(checkpoint['encoder_classes']['last_name_f4']) + 10,\n",
    "        'first_name_l4': len(checkpoint['encoder_classes']['first_name_l4']) + 10,\n",
    "        'last_name_l4': len(checkpoint['encoder_classes']['last_name_l4']) + 10\n",
    "    }\n",
    "    \n",
    "    # Recreate embedding layers\n",
    "    embedding_layers = {\n",
    "        'first_name': torch.nn.Embedding(vocab_sizes['first_name'], embedding_dim),\n",
    "        'last_name': torch.nn.Embedding(vocab_sizes['last_name'], embedding_dim),\n",
    "        'first_name_f4': torch.nn.Embedding(vocab_sizes['first_name_f4'], embedding_dim // 2),\n",
    "        'last_name_f4': torch.nn.Embedding(vocab_sizes['last_name_f4'], embedding_dim // 2),\n",
    "        'first_name_l4': torch.nn.Embedding(vocab_sizes['first_name_l4'], embedding_dim // 2),\n",
    "        'last_name_l4': torch.nn.Embedding(vocab_sizes['last_name_l4'], embedding_dim // 2)\n",
    "    }\n",
    "    \n",
    "    # Load weights\n",
    "    for name in embedding_layers.keys():\n",
    "        embedding_layers[name].load_state_dict(checkpoint['embedding_layers'][name])\n",
    "        embedding_layers[name].eval()\n",
    "    \n",
    "    # Load linear layers\n",
    "    linear1 = torch.nn.Linear(checkpoint['linear1']['weight'].shape[1], checkpoint['linear2']['weight'].shape[1])\n",
    "    linear2 = torch.nn.Linear(checkpoint['linear2']['weight'].shape[1], 1)\n",
    "    linear1.load_state_dict(checkpoint['linear1'])\n",
    "    linear2.load_state_dict(checkpoint['linear2'])\n",
    "    linear1.eval()\n",
    "    linear2.eval()\n",
    "    \n",
    "    # Recreate encoders\n",
    "    encoders = {}\n",
    "    for name in ['first_name', 'last_name', 'first_name_f4', 'last_name_f4', 'first_name_l4', 'last_name_l4']:\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.classes_ = checkpoint['encoder_classes'][name]\n",
    "        encoders[name] = encoder\n",
    "    \n",
    "    return {\n",
    "        'embedding_layers': embedding_layers,\n",
    "        'linear1': linear1,\n",
    "        'linear2': linear2,\n",
    "        'encoders': encoders,\n",
    "        'feature_columns': checkpoint['feature_columns'],\n",
    "        'encoded_indices': checkpoint['encoded_indices']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_single_name(first_name, last_name, encoders):\n",
    "    \n",
    "    # Extract name fragments\n",
    "    first_name_f4 = str(first_name)[:4] if pd.notna(first_name) and first_name != '' else 'unknown'\n",
    "    last_name_f4 = str(last_name)[:4] if pd.notna(last_name) and last_name != '' else 'unknown'\n",
    "    first_name_l4 = str(first_name)[-4:] if pd.notna(first_name) and len(str(first_name)) >= 4 else 'unknown'\n",
    "    last_name_l4 = str(last_name)[-4:] if pd.notna(last_name) and len(str(last_name)) >= 4 else 'unknown'\n",
    "    \n",
    "    first_name = 'unknown' if pd.isna(first_name) or first_name == '' else first_name\n",
    "    last_name = 'unknown' if pd.isna(last_name) or last_name == '' else last_name\n",
    "    \n",
    "    # Encode all name components\n",
    "    encoded = {}\n",
    "    for encoder_name, value in [\n",
    "        ('first_name', first_name),\n",
    "        ('last_name', last_name),\n",
    "        ('first_name_f4', first_name_f4),\n",
    "        ('last_name_f4', last_name_f4),\n",
    "        ('first_name_l4', first_name_l4),\n",
    "        ('last_name_l4', last_name_l4)\n",
    "    ]:\n",
    "        encoder = encoders[encoder_name]\n",
    "        try:\n",
    "            encoded[encoder_name] = encoder.transform([value])[0]\n",
    "        except ValueError:\n",
    "            # Handle unseen names\n",
    "            encoded[encoder_name] = encoder.transform(['unknown'])[0]\n",
    "    \n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_name(model_dict, encoded, threshold=0.5):\n",
    "    \n",
    "    # Create dummy numeric features (zeros) - adjust if you have actual numeric features\n",
    "    numeric_features = np.zeros((1, len(model_dict['feature_columns']) - 6), dtype=np.float32)  # 6 encoded columns\n",
    "    numeric_tensor = torch.tensor(numeric_features, dtype=torch.float32)\n",
    "    \n",
    "    # Get all embeddings\n",
    "    with torch.no_grad():\n",
    "        first_name_emb = model_dict['embedding_layers']['first_name'](\n",
    "            torch.tensor([encoded['first_name']], dtype=torch.long)\n",
    "        )\n",
    "        last_name_emb = model_dict['embedding_layers']['last_name'](\n",
    "            torch.tensor([encoded['last_name']], dtype=torch.long)\n",
    "        )\n",
    "        first_name_f4_emb = model_dict['embedding_layers']['first_name_f4'](\n",
    "            torch.tensor([encoded['first_name_f4']], dtype=torch.long)\n",
    "        )\n",
    "        last_name_f4_emb = model_dict['embedding_layers']['last_name_f4'](\n",
    "            torch.tensor([encoded['last_name_f4']], dtype=torch.long)\n",
    "        )\n",
    "        first_name_l4_emb = model_dict['embedding_layers']['first_name_l4'](\n",
    "            torch.tensor([encoded['first_name_l4']], dtype=torch.long)\n",
    "        )\n",
    "        last_name_l4_emb = model_dict['embedding_layers']['last_name_l4'](\n",
    "            torch.tensor([encoded['last_name_l4']], dtype=torch.long)\n",
    "        )\n",
    "        \n",
    "        # Combine all features\n",
    "        combined = torch.cat([\n",
    "            numeric_tensor,\n",
    "            first_name_emb,\n",
    "            last_name_emb,\n",
    "            first_name_f4_emb,\n",
    "            last_name_f4_emb,\n",
    "            first_name_l4_emb,\n",
    "            last_name_l4_emb\n",
    "        ], dim=1)\n",
    "        \n",
    "        # Forward pass\n",
    "        hidden = torch.relu(model_dict['linear1'](combined))\n",
    "        output = torch.sigmoid(model_dict['linear2'](hidden))\n",
    "        \n",
    "        probability = output.item()\n",
    "        prediction = probability > threshold\n",
    "        \n",
    "        return prediction, probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'embedding_layers': {'first_name': Embedding(98633, 32),\n",
       "  'last_name': Embedding(450592, 32),\n",
       "  'first_name_f4': Embedding(27444, 16),\n",
       "  'last_name_f4': Embedding(51515, 16),\n",
       "  'first_name_l4': Embedding(26054, 16),\n",
       "  'last_name_l4': Embedding(48417, 16)},\n",
       " 'linear1': Linear(in_features=128, out_features=128, bias=True),\n",
       " 'linear2': Linear(in_features=128, out_features=1, bias=True),\n",
       " 'encoders': {'first_name': LabelEncoder(),\n",
       "  'last_name': LabelEncoder(),\n",
       "  'first_name_f4': LabelEncoder(),\n",
       "  'last_name_f4': LabelEncoder(),\n",
       "  'first_name_l4': LabelEncoder(),\n",
       "  'last_name_l4': LabelEncoder()},\n",
       " 'feature_columns': ['first_name_encoded',\n",
       "  'last_name_encoded',\n",
       "  'first_name_f4_encoded',\n",
       "  'last_name_f4_encoded',\n",
       "  'first_name_l4_encoded',\n",
       "  'last_name_l4_encoded'],\n",
       " 'encoded_indices': {'first_name_encoded': 0,\n",
       "  'last_name_encoded': 1,\n",
       "  'first_name_f4_encoded': 2,\n",
       "  'last_name_f4_encoded': 3,\n",
       "  'first_name_l4_encoded': 4,\n",
       "  'last_name_l4_encoded': 5}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer = load_model(\"./models/ethnicia_classifier_20_best.pt\")\n",
    "infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, 6.736971727150376e-07)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix the thing where it can't handle unseen names\n",
    "pred, prob = predict_single_name(infer, preprocess_single_name(\"mahmood\", \"khan\", infer[\"encoders\"]))\n",
    "pred, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_df(donors, infer, threshold=0.5):\n",
    "    \n",
    "    print(\"Preprocessing names...\")\n",
    "    donors = donors.copy()\n",
    "    \n",
    "    donors['firstname'] = donors['firstname'].fillna('unknown')\n",
    "    donors['lastname'] = donors['lastname'].fillna('unknown')\n",
    "    donors['first_name_f4'] = donors['firstname'].str[:4].fillna('unknown')\n",
    "    donors['last_name_f4'] = donors['lastname'].str[:4].fillna('unknown')\n",
    "    donors['first_name_l4'] = donors['firstname'].str[-4:].fillna('unknown')\n",
    "    donors['last_name_l4'] = donors['lastname'].str[-4:].fillna('unknown')\n",
    "    donors = donors[(donors['firstname'] != 'unknown') & (donors['lastname'] != 'unknown')]\n",
    "    \n",
    "    # Encode all names vectorized\n",
    "    encoders = infer['encoders']\n",
    "    encoded_data = {}\n",
    "    for col, encoder_name in [\n",
    "        ('firstname', 'first_name'),\n",
    "        ('lastname', 'last_name'),\n",
    "        ('first_name_f4', 'first_name_f4'),\n",
    "        ('last_name_f4', 'last_name_f4'),\n",
    "        ('first_name_l4', 'first_name_l4'),\n",
    "        ('last_name_l4', 'last_name_l4')\n",
    "    ]:\n",
    "        \n",
    "        encoder = encoders[encoder_name]\n",
    "        # Map unseen values to 'unknown'\n",
    "        try:\n",
    "            valid_mask = donors[col].isin(encoder.classes_)\n",
    "            encoded_col = donors[col].where(valid_mask, 'unknown')\n",
    "            encoded_data[encoder_name] = encoder.transform(encoded_col)\n",
    "        except:\n",
    "            print(col)\n",
    "            print(encoder_name)\n",
    "            print(pd.Series(valid_mask).value_counts())\n",
    "    \n",
    "    # Convert to tensors\n",
    "    print(\"Converting to tensors...\")\n",
    "    # Create numeric features tensor (zeros if no numeric features)\n",
    "    numeric_features = np.zeros((len(donors), len(infer['feature_columns']) - 6), dtype=np.float32)\n",
    "    numeric_tensor = torch.tensor(numeric_features, dtype=torch.float32)\n",
    "    \n",
    "    # Create all embedding tensors\n",
    "    embedding_tensors = []\n",
    "    for encoder_name in ['first_name', 'last_name', 'first_name_f4', 'last_name_f4', 'first_name_l4', 'last_name_l4']:\n",
    "        ids_tensor = torch.tensor(encoded_data[encoder_name], dtype=torch.long)\n",
    "        emb_layer = infer['embedding_layers'][encoder_name]\n",
    "        with torch.no_grad():\n",
    "            emb_tensor = emb_layer(ids_tensor)\n",
    "        embedding_tensors.append(emb_tensor)\n",
    "    \n",
    "    # Combine all features\n",
    "    print(\"Running model predictions...\")\n",
    "    with torch.no_grad():\n",
    "        combined = torch.cat([numeric_tensor] + embedding_tensors, dim=1)\n",
    "        hidden = torch.relu(infer['linear1'](combined))\n",
    "        outputs = torch.sigmoid(infer['linear2'](hidden))\n",
    "        probabilities = outputs.squeeze().numpy()\n",
    "    \n",
    "    # Apply threshold\n",
    "    predictions = probabilities > threshold\n",
    "    \n",
    "    # Add results to DataFrame\n",
    "    donors['model'] = predictions\n",
    "    donors['model_prob'] = probabilities\n",
    "    donors.drop(['first_name_f4', 'last_name_f4', 'first_name_l4', 'last_name_l4'], axis=1, inplace=True, errors='ignore')\n",
    "    \n",
    "    print(\"Classification complete!\")\n",
    "    \n",
    "    # Print summary\n",
    "    indian_count = predictions.sum()\n",
    "    total_count = len(donors)\n",
    "    print(f\"\\nIndian names: {indian_count} ({indian_count/total_count*100:.2f}%)\")\n",
    "    print(f\"Non-Indian names: {total_count - indian_count} ({(total_count - indian_count)/total_count*100:.2f}%)\")\n",
    "    \n",
    "    return donors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing names...\n",
      "first_name_f4\n",
      "first_name_f4\n",
      "first_name_f4\n",
      "True     3532459\n",
      "False      56461\n",
      "Name: count, dtype: int64\n",
      "last_name_f4\n",
      "last_name_f4\n",
      "last_name_f4\n",
      "True     3588717\n",
      "False        203\n",
      "Name: count, dtype: int64\n",
      "first_name_l4\n",
      "first_name_l4\n",
      "first_name_l4\n",
      "True     2893303\n",
      "False     695617\n",
      "Name: count, dtype: int64\n",
      "last_name_l4\n",
      "last_name_l4\n",
      "last_name_l4\n",
      "True     3588717\n",
      "False        203\n",
      "Name: count, dtype: int64\n",
      "Converting to tensors...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'first_name_f4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[161], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m donors_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdonors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m donors_pred[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "Cell \u001b[1;32mIn[160], line 46\u001b[0m, in \u001b[0;36mpredict_df\u001b[1;34m(donors, infer, threshold)\u001b[0m\n\u001b[0;32m     44\u001b[0m embedding_tensors \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m encoder_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_name_f4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_name_f4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirst_name_l4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_name_l4\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m---> 46\u001b[0m     ids_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mencoded_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mencoder_name\u001b[49m\u001b[43m]\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[0;32m     47\u001b[0m     emb_layer \u001b[38;5;241m=\u001b[39m infer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding_layers\u001b[39m\u001b[38;5;124m'\u001b[39m][encoder_name]\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "\u001b[1;31mKeyError\u001b[0m: 'first_name_f4'"
     ]
    }
   ],
   "source": [
    "donors_pred = predict_df(donors, infer)\n",
    "donors_pred[\"model\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
