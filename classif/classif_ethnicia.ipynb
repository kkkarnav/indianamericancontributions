{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tqdm.pandas()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 20\n",
    "df = f\"../data/CampaignFin{year}/indivs{year}.txt\"\n",
    "donors_csv = f\"../data/CampaignFin{year}/donors_state{year}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contrib_id</th>\n",
       "      <th>name</th>\n",
       "      <th>name_new</th>\n",
       "      <th>orgname</th>\n",
       "      <th>ultorg</th>\n",
       "      <th>realcode</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>employer</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>total_donated</th>\n",
       "      <th>donation_count</th>\n",
       "      <th>avg_donation</th>\n",
       "      <th>med_donation</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>ACTBLUE</td>\n",
       "      <td>actblue actblue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y4000</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WASHINGTON</td>\n",
       "      <td>CA</td>\n",
       "      <td>1.261253e+09</td>\n",
       "      <td>25821</td>\n",
       "      <td>4.884603e+04</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>actblue</td>\n",
       "      <td>actblue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U00000037041</td>\n",
       "      <td>BLOOMBERG, MICHAEL R</td>\n",
       "      <td>michael r bloomberg</td>\n",
       "      <td>[Candidate Contribution]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z9000</td>\n",
       "      <td>M</td>\n",
       "      <td>FOUNDER</td>\n",
       "      <td>BLOOMBERG INC.</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>1.127731e+09</td>\n",
       "      <td>958</td>\n",
       "      <td>1.177172e+06</td>\n",
       "      <td>682.5</td>\n",
       "      <td>michael r</td>\n",
       "      <td>bloomberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U00000036521</td>\n",
       "      <td>STEYER, TOM</td>\n",
       "      <td>tom steyer</td>\n",
       "      <td>[Candidate Contribution]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Z9000</td>\n",
       "      <td>M</td>\n",
       "      <td>PRESIDENTIAL CANDIDATE</td>\n",
       "      <td>SELF-EMPLOYED</td>\n",
       "      <td>SAN FRANCISCO</td>\n",
       "      <td>CA</td>\n",
       "      <td>3.794782e+08</td>\n",
       "      <td>756</td>\n",
       "      <td>5.019553e+05</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>tom</td>\n",
       "      <td>steyer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U00000046841</td>\n",
       "      <td>MELLON, TIMOTHY</td>\n",
       "      <td>timothy mellon</td>\n",
       "      <td>Investments</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F7000</td>\n",
       "      <td>M</td>\n",
       "      <td>INVESTMENTS</td>\n",
       "      <td>SELF-EMPLOYED</td>\n",
       "      <td>SARATOGA</td>\n",
       "      <td>WY</td>\n",
       "      <td>4.513356e+07</td>\n",
       "      <td>23</td>\n",
       "      <td>1.962328e+06</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>timothy</td>\n",
       "      <td>mellon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U0000000310A</td>\n",
       "      <td>ADELSON, MIRIAM</td>\n",
       "      <td>miriam adelson</td>\n",
       "      <td>Adelson Clinic for Drug Abuse Treatment &amp; Rese...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H3200</td>\n",
       "      <td>F</td>\n",
       "      <td>PHYSICIAN</td>\n",
       "      <td>ADELSON CLINIC</td>\n",
       "      <td>LAS VEGAS</td>\n",
       "      <td>NV</td>\n",
       "      <td>4.499955e+07</td>\n",
       "      <td>124</td>\n",
       "      <td>3.628996e+05</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>miriam</td>\n",
       "      <td>adelson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>U00000003101</td>\n",
       "      <td>ADELSON, SHELDON G</td>\n",
       "      <td>sheldon g adelson</td>\n",
       "      <td>Las Vegas Sands</td>\n",
       "      <td>NaN</td>\n",
       "      <td>G6500</td>\n",
       "      <td>M</td>\n",
       "      <td>CEO</td>\n",
       "      <td>LAS VEGAS SANDS CORPORATION</td>\n",
       "      <td>LAS VEGAS</td>\n",
       "      <td>NV</td>\n",
       "      <td>4.484795e+07</td>\n",
       "      <td>119</td>\n",
       "      <td>3.768735e+05</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>sheldon g</td>\n",
       "      <td>adelson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>U00000036901</td>\n",
       "      <td>UIHLEIN, RICHARD</td>\n",
       "      <td>richard uihlein</td>\n",
       "      <td>Uline Inc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M7000</td>\n",
       "      <td>M</td>\n",
       "      <td>CEO</td>\n",
       "      <td>ULINE</td>\n",
       "      <td>LAKE FOREST</td>\n",
       "      <td>IL</td>\n",
       "      <td>3.536433e+07</td>\n",
       "      <td>319</td>\n",
       "      <td>1.108600e+05</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>richard</td>\n",
       "      <td>uihlein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>U00000036551</td>\n",
       "      <td>GRIFFIN, KENNETH</td>\n",
       "      <td>kenneth griffin</td>\n",
       "      <td>Citadel LLC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F2700</td>\n",
       "      <td>M</td>\n",
       "      <td>FOUNDER  CEO</td>\n",
       "      <td>CITADEL LLC</td>\n",
       "      <td>CHICAGO</td>\n",
       "      <td>IL</td>\n",
       "      <td>3.366763e+07</td>\n",
       "      <td>188</td>\n",
       "      <td>1.790832e+05</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>kenneth</td>\n",
       "      <td>griffin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>U00000003611</td>\n",
       "      <td>SCHWARZMAN, STEPHEN A</td>\n",
       "      <td>stephen a schwarzman</td>\n",
       "      <td>Blackstone Group</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F2600</td>\n",
       "      <td>M</td>\n",
       "      <td>CHAIRMAN</td>\n",
       "      <td>BLACKSTONE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "      <td>3.345400e+07</td>\n",
       "      <td>226</td>\n",
       "      <td>1.480265e+05</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>stephen a</td>\n",
       "      <td>schwarzman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>U00000046781</td>\n",
       "      <td>JURVETSON, KARLA</td>\n",
       "      <td>karla jurvetson</td>\n",
       "      <td>Karla T Jurvetson MD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H1110</td>\n",
       "      <td>F</td>\n",
       "      <td>PHYSICIAN</td>\n",
       "      <td>SELF</td>\n",
       "      <td>LOS ALTOS</td>\n",
       "      <td>CA</td>\n",
       "      <td>3.308810e+07</td>\n",
       "      <td>914</td>\n",
       "      <td>3.620142e+04</td>\n",
       "      <td>2800.0</td>\n",
       "      <td>karla</td>\n",
       "      <td>jurvetson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     contrib_id                   name              name_new  \\\n",
       "0                              ACTBLUE       actblue actblue   \n",
       "1  U00000037041   BLOOMBERG, MICHAEL R   michael r bloomberg   \n",
       "2  U00000036521            STEYER, TOM            tom steyer   \n",
       "3  U00000046841        MELLON, TIMOTHY        timothy mellon   \n",
       "4  U0000000310A        ADELSON, MIRIAM        miriam adelson   \n",
       "5  U00000003101     ADELSON, SHELDON G     sheldon g adelson   \n",
       "6  U00000036901       UIHLEIN, RICHARD       richard uihlein   \n",
       "7  U00000036551       GRIFFIN, KENNETH       kenneth griffin   \n",
       "8  U00000003611  SCHWARZMAN, STEPHEN A  stephen a schwarzman   \n",
       "9  U00000046781       JURVETSON, KARLA       karla jurvetson   \n",
       "\n",
       "                                             orgname ultorg realcode gender  \\\n",
       "0                                                NaN    NaN    Y4000          \n",
       "1                           [Candidate Contribution]    NaN    Z9000      M   \n",
       "2                           [Candidate Contribution]    NaN    Z9000      M   \n",
       "3                                        Investments    NaN    F7000      M   \n",
       "4  Adelson Clinic for Drug Abuse Treatment & Rese...    NaN    H3200      F   \n",
       "5                                    Las Vegas Sands    NaN    G6500      M   \n",
       "6                                          Uline Inc    NaN    M7000      M   \n",
       "7                                        Citadel LLC    NaN    F2700      M   \n",
       "8                                   Blackstone Group    NaN    F2600      M   \n",
       "9                               Karla T Jurvetson MD    NaN    H1110      F   \n",
       "\n",
       "               occupation                     employer           city state  \\\n",
       "0                     NaN                          NaN     WASHINGTON    CA   \n",
       "1                 FOUNDER               BLOOMBERG INC.       NEW YORK    NY   \n",
       "2  PRESIDENTIAL CANDIDATE                SELF-EMPLOYED  SAN FRANCISCO    CA   \n",
       "3             INVESTMENTS                SELF-EMPLOYED       SARATOGA    WY   \n",
       "4               PHYSICIAN               ADELSON CLINIC      LAS VEGAS    NV   \n",
       "5                     CEO  LAS VEGAS SANDS CORPORATION      LAS VEGAS    NV   \n",
       "6                     CEO                        ULINE    LAKE FOREST    IL   \n",
       "7            FOUNDER  CEO                  CITADEL LLC        CHICAGO    IL   \n",
       "8                CHAIRMAN                   BLACKSTONE       NEW YORK    NY   \n",
       "9               PHYSICIAN                         SELF      LOS ALTOS    CA   \n",
       "\n",
       "   total_donated  donation_count  avg_donation  med_donation  firstname  \\\n",
       "0   1.261253e+09           25821  4.884603e+04        1000.0    actblue   \n",
       "1   1.127731e+09             958  1.177172e+06         682.5  michael r   \n",
       "2   3.794782e+08             756  5.019553e+05        2800.0        tom   \n",
       "3   4.513356e+07              23  1.962328e+06        2800.0    timothy   \n",
       "4   4.499955e+07             124  3.628996e+05        2800.0     miriam   \n",
       "5   4.484795e+07             119  3.768735e+05        2800.0  sheldon g   \n",
       "6   3.536433e+07             319  1.108600e+05        2800.0    richard   \n",
       "7   3.366763e+07             188  1.790832e+05        2800.0    kenneth   \n",
       "8   3.345400e+07             226  1.480265e+05        2800.0  stephen a   \n",
       "9   3.308810e+07             914  3.620142e+04        2800.0      karla   \n",
       "\n",
       "     lastname  \n",
       "0     actblue  \n",
       "1   bloomberg  \n",
       "2      steyer  \n",
       "3      mellon  \n",
       "4     adelson  \n",
       "5     adelson  \n",
       "6     uihlein  \n",
       "7     griffin  \n",
       "8  schwarzman  \n",
       "9   jurvetson  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors = pd.read_csv(donors_csv)\n",
    "donors[\"firstname\"] = donors[\"name\"].apply(lambda x: str(x).split(\",\")[-1].lower().strip())\n",
    "donors[\"lastname\"] = donors[\"name\"].apply(lambda x: str(x).split(\",\")[0].lower().strip())\n",
    "donors.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstname_ratios = pd.read_csv(\"../output/USIN_firstnames_ratios.csv\")\n",
    "lastname_ratios = pd.read_csv(\"../output/USIN_lastnames_ratios.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstname_ratio_dict = firstname_ratios.set_index(firstname_ratios['firstname'].str.strip().str.lower())['ratio'].to_dict()\n",
    "lastname_ratio_dict = lastname_ratios.set_index(lastname_ratios['lastname'].str.strip().str.lower())['ratio'].to_dict()\n",
    "\n",
    "donors['combined_ratio'] = (\n",
    "    donors['firstname'].map(firstname_ratio_dict).fillna(0) + \n",
    "    donors['lastname'].map(lastname_ratio_dict).fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the most common indian last names\n",
    "indian_firstnames = set(firstname_ratios[firstname_ratios[\"ratio\"] >= 8][\"firstname\"].str.lower())\n",
    "indian_lastnames = set(lastname_ratios[lastname_ratios[\"ratio\"] >= 5][\"lastname\"].str.lower())\n",
    "unindian_firstnames = set(firstname_ratios[firstname_ratios[\"ratio\"] <= 0.05][\"firstname\"].str.lower())\n",
    "unindian_lastnames = set(lastname_ratios[lastname_ratios[\"ratio\"] <= 0.05][\"lastname\"].str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indian\n",
       "False    3545523\n",
       "True       43413\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors[\"indian_first\"] = np.where(donors[\"firstname\"].str.lower().isin(indian_firstnames) & ~donors[\"lastname\"].str.lower().isin(unindian_lastnames), True, False)\n",
    "donors[\"indian_last\"] = np.where(donors[\"lastname\"].str.lower().isin(indian_lastnames) & ~donors[\"firstname\"].str.lower().isin(unindian_firstnames), True, False)\n",
    "donors[\"indian\"] = np.where((donors[\"combined_ratio\"] >= 15) | (donors[\"indian_first\"] == True) | (donors[\"indian_last\"] == True), True, False)\n",
    "donors[\"indian\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_us = pd.read_csv(\"../data/US.csv\")\\ndf_us.columns = [\\'firstname\\', \\'lastname\\', \\'gender\\', \\'ethnicity\\']\\ndf_us[\\'firstname\\'] = df_us[\\'firstname\\'].apply(lambda x: x.split(\" \")[0].strip() if \" \" in str(x) else str(x).strip())\\ndf_us[\\'lastname\\'] = df_us[\\'lastname\\'].apply(lambda x: x.split(\" \")[-1].strip() if \" \" in str(x) else str(x).strip())\\ndf_us[\\'name\\'] = df_us[\\'firstname\\'].apply(lambda x: x.lower()) + \\' \\' + df_us[\\'lastname\\'].apply(lambda x: x.lower())\\ndf_us[\"indian\"] = df_us[\"ethnicity\"].apply(lambda x: False)\\n\\ndf_us = df_us[\\n    (df_us[\\'firstname\\'].str.match(r\\'^[A-Za-z]+$\\', na=False)) & \\n    (df_us[\\'firstname\\'].str.len() > 1) &\\n    (df_us[\\'firstname\\'].str.lower() != \\'nan\\') &\\n    (df_us[\\'lastname\\'].str.match(r\\'^[A-Za-z]+$\\', na=False)) &\\n    (df_us[\\'lastname\\'].str.len() > 1) &\\n    (df_us[\\'lastname\\'].str.lower() != \\'nan\\')\\n]\\n\\ndf_us = df_us[[\\'firstname\\', \\'lastname\\', \\'name\\', \\'indian\\']]\\ndf_us.head(10)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/philipperemy/name-dataset\n",
    "'''df_us = pd.read_csv(\"../data/US.csv\")\n",
    "df_us.columns = ['firstname', 'lastname', 'gender', 'ethnicity']\n",
    "df_us['firstname'] = df_us['firstname'].apply(lambda x: x.split(\" \")[0].strip() if \" \" in str(x) else str(x).strip())\n",
    "df_us['lastname'] = df_us['lastname'].apply(lambda x: x.split(\" \")[-1].strip() if \" \" in str(x) else str(x).strip())\n",
    "df_us['name'] = df_us['firstname'].apply(lambda x: x.lower()) + ' ' + df_us['lastname'].apply(lambda x: x.lower())\n",
    "df_us[\"indian\"] = df_us[\"ethnicity\"].apply(lambda x: False)\n",
    "\n",
    "df_us = df_us[\n",
    "    (df_us['firstname'].str.match(r'^[A-Za-z]+$', na=False)) & \n",
    "    (df_us['firstname'].str.len() > 1) &\n",
    "    (df_us['firstname'].str.lower() != 'nan') &\n",
    "    (df_us['lastname'].str.match(r'^[A-Za-z]+$', na=False)) &\n",
    "    (df_us['lastname'].str.len() > 1) &\n",
    "    (df_us['lastname'].str.lower() != 'nan')\n",
    "]\n",
    "\n",
    "df_us = df_us[['firstname', 'lastname', 'name', 'indian']]\n",
    "df_us.head(10)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"total_names = len(df_us)\\n\\nfirstname_counts = df_us['firstname'].value_counts().reset_index().rename(columns={'count': 'firstname_count'})\\nfirstname_counts['firstname_rate'] = (firstname_counts['firstname_count'] / len(df_us)) * 100\\n\\nlastname_counts = df_us['lastname'].value_counts().reset_index().rename(columns={'count': 'lastname_count'})\\nlastname_counts['lastname_rate'] = (lastname_counts['lastname_count'] / len(df_us)) * 100\\n\\ndf_us = df_us.merge(firstname_counts[['firstname', 'firstname_count', 'firstname_rate']], on='firstname', how='left')\\ndf_us = df_us.merge(lastname_counts[['lastname', 'lastname_count', 'lastname_rate']], on='lastname', how='left')\\ndf_us\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''total_names = len(df_us)\n",
    "\n",
    "firstname_counts = df_us['firstname'].value_counts().reset_index().rename(columns={'count': 'firstname_count'})\n",
    "firstname_counts['firstname_rate'] = (firstname_counts['firstname_count'] / len(df_us)) * 100\n",
    "\n",
    "lastname_counts = df_us['lastname'].value_counts().reset_index().rename(columns={'count': 'lastname_count'})\n",
    "lastname_counts['lastname_rate'] = (lastname_counts['lastname_count'] / len(df_us)) * 100\n",
    "\n",
    "df_us = df_us.merge(firstname_counts[['firstname', 'firstname_count', 'firstname_rate']], on='firstname', how='left')\n",
    "df_us = df_us.merge(lastname_counts[['lastname', 'lastname_count', 'lastname_rate']], on='lastname', how='left')\n",
    "df_us'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# https://github.com/philipperemy/name-dataset\\ndf_indian = pd.read_csv(\"../data/IN.csv\")\\ndf_indian.columns = [\\'firstname\\', \\'lastname\\', \\'gender\\', \\'ethnicity\\']\\ndf_indian[\\'firstname\\'] = df_indian[\\'firstname\\'].apply(lambda x: x.split(\" \")[0].strip() if \" \" in str(x) else str(x).strip())\\ndf_indian[\\'lastname\\'] = df_indian[\\'lastname\\'].apply(lambda x: x.split(\" \")[-1].strip() if \" \" in str(x) else str(x).strip())\\ndf_indian[\\'name\\'] = df_indian[\\'firstname\\'].apply(lambda x: x.lower()) + \\' \\' + df_indian[\\'lastname\\'].apply(lambda x: x.lower())\\ndf_indian[\"indian\"] = df_indian[\"ethnicity\"].apply(lambda x: True)\\n\\ndf_indian = df_indian[\\n    (df_indian[\\'firstname\\'].str.match(r\\'^[A-Za-z]+$\\', na=False)) & \\n    (df_indian[\\'firstname\\'].str.len() > 1) &\\n    (df_indian[\\'firstname\\'].str.lower() != \\'nan\\') &\\n    (df_indian[\\'lastname\\'].str.match(r\\'^[A-Za-z]+$\\', na=False)) &\\n    (df_indian[\\'lastname\\'].str.len() > 1) &\\n    (df_indian[\\'lastname\\'].str.lower() != \\'nan\\')\\n]\\n\\ndf_indian = df_indian[[\\'firstname\\', \\'lastname\\', \\'name\\', \\'indian\\']]\\ndf_indian.head(10)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# https://github.com/philipperemy/name-dataset\n",
    "df_indian = pd.read_csv(\"../data/IN.csv\")\n",
    "df_indian.columns = ['firstname', 'lastname', 'gender', 'ethnicity']\n",
    "df_indian['firstname'] = df_indian['firstname'].apply(lambda x: x.split(\" \")[0].strip() if \" \" in str(x) else str(x).strip())\n",
    "df_indian['lastname'] = df_indian['lastname'].apply(lambda x: x.split(\" \")[-1].strip() if \" \" in str(x) else str(x).strip())\n",
    "df_indian['name'] = df_indian['firstname'].apply(lambda x: x.lower()) + ' ' + df_indian['lastname'].apply(lambda x: x.lower())\n",
    "df_indian[\"indian\"] = df_indian[\"ethnicity\"].apply(lambda x: True)\n",
    "\n",
    "df_indian = df_indian[\n",
    "    (df_indian['firstname'].str.match(r'^[A-Za-z]+$', na=False)) & \n",
    "    (df_indian['firstname'].str.len() > 1) &\n",
    "    (df_indian['firstname'].str.lower() != 'nan') &\n",
    "    (df_indian['lastname'].str.match(r'^[A-Za-z]+$', na=False)) &\n",
    "    (df_indian['lastname'].str.len() > 1) &\n",
    "    (df_indian['lastname'].str.lower() != 'nan')\n",
    "]\n",
    "\n",
    "df_indian = df_indian[['firstname', 'lastname', 'name', 'indian']]\n",
    "df_indian.head(10)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"total_names = len(df_indian)\\n\\nfirstname_counts = df_indian['firstname'].value_counts().reset_index().rename(columns={'count': 'firstname_count'})\\nfirstname_counts['firstname_rate'] = (firstname_counts['firstname_count'] / len(df_indian)) * 100\\n\\nlastname_counts = df_indian['lastname'].value_counts().reset_index().rename(columns={'count': 'lastname_count'})\\nlastname_counts['lastname_rate'] = (lastname_counts['lastname_count'] / len(df_indian)) * 100\\n\\ndf_indian = df_indian.merge(firstname_counts[['firstname', 'firstname_count', 'firstname_rate']], on='firstname', how='left')\\ndf_indian = df_indian.merge(lastname_counts[['lastname', 'lastname_count', 'lastname_rate']], on='lastname', how='left')\\ndf_indian\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''total_names = len(df_indian)\n",
    "\n",
    "firstname_counts = df_indian['firstname'].value_counts().reset_index().rename(columns={'count': 'firstname_count'})\n",
    "firstname_counts['firstname_rate'] = (firstname_counts['firstname_count'] / len(df_indian)) * 100\n",
    "\n",
    "lastname_counts = df_indian['lastname'].value_counts().reset_index().rename(columns={'count': 'lastname_count'})\n",
    "lastname_counts['lastname_rate'] = (lastname_counts['lastname_count'] / len(df_indian)) * 100\n",
    "\n",
    "df_indian = df_indian.merge(firstname_counts[['firstname', 'firstname_count', 'firstname_rate']], on='firstname', how='left')\n",
    "df_indian = df_indian.merge(lastname_counts[['lastname', 'lastname_count', 'lastname_rate']], on='lastname', how='left')\n",
    "df_indian'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_combined = pd.concat([df_us, df_indian], ignore_index=True)\\ndf_combined.to_csv(\"../output/USIN.csv\", index=False)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_combined = pd.concat([df_us, df_indian], ignore_index=True)\n",
    "df_combined.to_csv(\"../output/USIN.csv\", index=False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>name</th>\n",
       "      <th>indian</th>\n",
       "      <th>firstname_count</th>\n",
       "      <th>firstname_rate</th>\n",
       "      <th>lastname_count</th>\n",
       "      <th>lastname_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brandon</td>\n",
       "      <td>Sylvester</td>\n",
       "      <td>brandon sylvester</td>\n",
       "      <td>False</td>\n",
       "      <td>58421</td>\n",
       "      <td>0.189127</td>\n",
       "      <td>1272</td>\n",
       "      <td>0.004118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chris</td>\n",
       "      <td>Toussaint</td>\n",
       "      <td>chris toussaint</td>\n",
       "      <td>False</td>\n",
       "      <td>131039</td>\n",
       "      <td>0.424215</td>\n",
       "      <td>1691</td>\n",
       "      <td>0.005474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Willie</td>\n",
       "      <td>Gotti</td>\n",
       "      <td>willie gotti</td>\n",
       "      <td>False</td>\n",
       "      <td>10987</td>\n",
       "      <td>0.035568</td>\n",
       "      <td>693</td>\n",
       "      <td>0.002243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cristobal</td>\n",
       "      <td>Corona</td>\n",
       "      <td>cristobal corona</td>\n",
       "      <td>False</td>\n",
       "      <td>2640</td>\n",
       "      <td>0.008547</td>\n",
       "      <td>9672</td>\n",
       "      <td>0.031311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wilmer</td>\n",
       "      <td>Diaz</td>\n",
       "      <td>wilmer diaz</td>\n",
       "      <td>False</td>\n",
       "      <td>4269</td>\n",
       "      <td>0.013820</td>\n",
       "      <td>91634</td>\n",
       "      <td>0.296648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36734983</th>\n",
       "      <td>Vikas</td>\n",
       "      <td>Chakchanpur</td>\n",
       "      <td>vikas chakchanpur</td>\n",
       "      <td>True</td>\n",
       "      <td>8871</td>\n",
       "      <td>0.151765</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36734984</th>\n",
       "      <td>Dipu</td>\n",
       "      <td>Gupta</td>\n",
       "      <td>dipu gupta</td>\n",
       "      <td>True</td>\n",
       "      <td>1526</td>\n",
       "      <td>0.026107</td>\n",
       "      <td>43396</td>\n",
       "      <td>0.742419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36734985</th>\n",
       "      <td>Riya</td>\n",
       "      <td>Naharwal</td>\n",
       "      <td>riya naharwal</td>\n",
       "      <td>True</td>\n",
       "      <td>6367</td>\n",
       "      <td>0.108927</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36734986</th>\n",
       "      <td>Jashandeep</td>\n",
       "      <td>Hanjra</td>\n",
       "      <td>jashandeep hanjra</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36734987</th>\n",
       "      <td>Jony</td>\n",
       "      <td>Bindas</td>\n",
       "      <td>jony bindas</td>\n",
       "      <td>True</td>\n",
       "      <td>305</td>\n",
       "      <td>0.005218</td>\n",
       "      <td>66</td>\n",
       "      <td>0.001129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36734988 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           firstname     lastname               name  indian  firstname_count  \\\n",
       "0            Brandon    Sylvester  brandon sylvester   False            58421   \n",
       "1              Chris    Toussaint    chris toussaint   False           131039   \n",
       "2             Willie        Gotti       willie gotti   False            10987   \n",
       "3          Cristobal       Corona   cristobal corona   False             2640   \n",
       "4             Wilmer         Diaz        wilmer diaz   False             4269   \n",
       "...              ...          ...                ...     ...              ...   \n",
       "36734983       Vikas  Chakchanpur  vikas chakchanpur    True             8871   \n",
       "36734984        Dipu        Gupta         dipu gupta    True             1526   \n",
       "36734985        Riya     Naharwal      riya naharwal    True             6367   \n",
       "36734986  Jashandeep       Hanjra  jashandeep hanjra    True               17   \n",
       "36734987        Jony       Bindas        jony bindas    True              305   \n",
       "\n",
       "          firstname_rate  lastname_count  lastname_rate  \n",
       "0               0.189127            1272       0.004118  \n",
       "1               0.424215            1691       0.005474  \n",
       "2               0.035568             693       0.002243  \n",
       "3               0.008547            9672       0.031311  \n",
       "4               0.013820           91634       0.296648  \n",
       "...                  ...             ...            ...  \n",
       "36734983        0.151765               1       0.000017  \n",
       "36734984        0.026107           43396       0.742419  \n",
       "36734985        0.108927               8       0.000137  \n",
       "36734986        0.000291              43       0.000736  \n",
       "36734987        0.005218              66       0.001129  \n",
       "\n",
       "[36734988 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../output/USIN.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_features(train_data_label, output_file_path=\"USIN_features.csv\"):\n",
    "    # --------------------\n",
    "    # Load Data\n",
    "    # --------------------\n",
    "    \n",
    "    path = f\"../output/yearly/donors_{train_data_label}_pred_lastname.csv\"\n",
    "    train_data = pd.read_csv(path)\n",
    "        \n",
    "    train_data['id'] = range(1, len(train_data) + 1)\n",
    "    \n",
    "    # Clean data\n",
    "    train_data['firstname'] = train_data['firstname'].apply(lambda x: str(x).split(\" \")[0])\n",
    "    train_data = train_data.dropna(subset=['firstname', 'lastname', 'indian'])\n",
    "    \n",
    "    # --------------------\n",
    "    # Cutpoints\n",
    "    # --------------------\n",
    "    \n",
    "    c = 1\n",
    "    cutl = 10\n",
    "    \n",
    "    # --------------------\n",
    "    # Feature Creation\n",
    "    # --------------------\n",
    "    \n",
    "    # 1. First four letters of the first/last name:\n",
    "    train_data['first_name_f4'] = train_data['firstname'].str[:4]\n",
    "    train_data['last_name_f4'] = train_data['lastname'].str[:4]\n",
    "    \n",
    "    # First Names - Indian probability\n",
    "    indian_count_fn = train_data[train_data['indian'] == True].groupby('first_name_f4').size()\n",
    "    indian_count_fn.name = 'pop_indian_f4'\n",
    "    train_data = train_data.merge(indian_count_fn, how='left', on='first_name_f4')\n",
    "    \n",
    "    mean_pop = train_data.groupby('first_name_f4')['pop_indian_f4'].transform('mean')\n",
    "    count = train_data.groupby('first_name_f4')['pop_indian_f4'].transform('count')\n",
    "    train_data['pop_fn_indian_f4'] = mean_pop / (count + c)\n",
    "    \n",
    "    # Last Names - Indian probability\n",
    "    indian_count_ln = train_data[train_data['indian'] == True].groupby('last_name_f4').size()\n",
    "    indian_count_ln.name = 'pop_indian_f4_ln'\n",
    "    train_data = train_data.merge(indian_count_ln, how='left', on='last_name_f4')\n",
    "    \n",
    "    mean_pop = train_data.groupby('last_name_f4')['pop_indian_f4_ln'].transform('mean')\n",
    "    count = train_data.groupby('last_name_f4')['pop_indian_f4_ln'].transform('count')\n",
    "    train_data['pop_ln_indian_f4'] = mean_pop / count\n",
    "    \n",
    "    train_data = train_data.drop(columns=['pop_indian_f4', 'pop_indian_f4_ln'])\n",
    "    train_data = train_data.fillna(0)\n",
    "    \n",
    "    # 2. Last four letters of the first/last name:\n",
    "    train_data['first_name_l4'] = train_data['firstname'].str[-4:]\n",
    "    train_data['last_name_l4'] = train_data['lastname'].str[-4:]\n",
    "    \n",
    "    # First Names - Indian probability\n",
    "    indian_count_fn = train_data[train_data['indian'] == True].groupby('first_name_l4').size()\n",
    "    indian_count_fn.name = 'pop_indian_l4'\n",
    "    train_data = train_data.merge(indian_count_fn, how='left', on='first_name_l4')\n",
    "    \n",
    "    mean_pop = train_data.groupby('first_name_l4')['pop_indian_l4'].transform('mean')\n",
    "    count = train_data.groupby('first_name_l4')['pop_indian_l4'].transform('count')\n",
    "    train_data['pop_fn_indian_l4'] = mean_pop / (count + c)\n",
    "    \n",
    "    # Last Names - Indian probability\n",
    "    indian_count_ln = train_data[train_data['indian'] == True].groupby('last_name_l4').size()\n",
    "    indian_count_ln.name = 'pop_indian_l4_ln'\n",
    "    train_data = train_data.merge(indian_count_ln, how='left', on='last_name_l4')\n",
    "    \n",
    "    mean_pop = train_data.groupby('last_name_l4')['pop_indian_l4_ln'].transform('mean')\n",
    "    count = train_data.groupby('last_name_l4')['pop_indian_l4_ln'].transform('count')\n",
    "    train_data['pop_ln_indian_l4'] = mean_pop / (count + c)\n",
    "    \n",
    "    train_data = train_data.drop(columns=['pop_indian_l4', 'pop_indian_l4_ln'])\n",
    "    train_data = train_data.fillna(0)\n",
    "    \n",
    "    # 3. Full first/last name:\n",
    "    # First Names - Indian probability\n",
    "    indian_count_fn = train_data[train_data['indian'] == True].groupby('firstname').size()\n",
    "    indian_count_fn.name = 'pop_indian_fn'\n",
    "    train_data = train_data.merge(indian_count_fn, how='left', on='firstname')\n",
    "    \n",
    "    mean_pop = train_data.groupby('firstname')['pop_indian_fn'].transform('mean')\n",
    "    count = train_data.groupby('firstname')['pop_indian_fn'].transform('count')\n",
    "    train_data['pop_fn_indian'] = mean_pop / (count + c)\n",
    "    \n",
    "    # Last Names - Indian probability\n",
    "    indian_count_ln = train_data[train_data['indian'] == True].groupby('lastname').size()\n",
    "    indian_count_ln.name = 'pop_indian_ln'\n",
    "    train_data = train_data.merge(indian_count_ln, how='left', on='lastname')\n",
    "    \n",
    "    mean_pop = train_data.groupby('lastname')['pop_indian_ln'].transform('mean')\n",
    "    count = train_data.groupby('lastname')['pop_indian_ln'].transform('count')\n",
    "    train_data['pop_ln_indian'] = mean_pop / (count + c)\n",
    "    \n",
    "    train_data = train_data.drop(columns=['pop_indian_fn', 'pop_indian_ln'])\n",
    "    train_data = train_data.fillna(0)\n",
    "    \n",
    "    # Indicator Low Frequency of Name:\n",
    "    train_data['first_name_low'] = (train_data.groupby('firstname')['firstname'].transform('count') < cutl).astype(int)\n",
    "    train_data['last_name_low'] = (train_data.groupby('lastname')['lastname'].transform('count') < cutl).astype(int)\n",
    "    \n",
    "    # Best Evidence\n",
    "    train_data['best_evidence_indian'] = train_data[['pop_ln_indian', 'pop_fn_indian']].max(axis=1)\n",
    "    \n",
    "    # Select final columns\n",
    "    final_columns = [\n",
    "        'id', 'firstname', 'lastname', 'indian', \n",
    "        'first_name_f4', 'first_name_l4',\n",
    "        'last_name_f4', 'last_name_l4',\n",
    "        'pop_ln_indian', 'pop_fn_indian',\n",
    "        'best_evidence_indian',\n",
    "        'pop_ln_indian_f4', 'pop_fn_indian_f4',\n",
    "        'pop_ln_indian_l4', 'pop_fn_indian_l4',\n",
    "        'last_name_low', 'first_name_low'\n",
    "    ]\n",
    "    \n",
    "    train_data = train_data[final_columns]\n",
    "    \n",
    "    # Save output\n",
    "    output_file_path = f\"../data/donors{train_data_label}_{output_file_path}\"\n",
    "    train_data.to_csv(output_file_path, index=False)\n",
    "    \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>firstname</th>\n",
       "      <th>lastname</th>\n",
       "      <th>indian</th>\n",
       "      <th>first_name_f4</th>\n",
       "      <th>first_name_l4</th>\n",
       "      <th>last_name_f4</th>\n",
       "      <th>last_name_l4</th>\n",
       "      <th>pop_ln_indian</th>\n",
       "      <th>pop_fn_indian</th>\n",
       "      <th>best_evidence_indian</th>\n",
       "      <th>pop_ln_indian_f4</th>\n",
       "      <th>pop_fn_indian_f4</th>\n",
       "      <th>pop_ln_indian_l4</th>\n",
       "      <th>pop_fn_indian_l4</th>\n",
       "      <th>last_name_low</th>\n",
       "      <th>first_name_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>actblue</td>\n",
       "      <td>actblue</td>\n",
       "      <td>False</td>\n",
       "      <td>actb</td>\n",
       "      <td>blue</td>\n",
       "      <td>actb</td>\n",
       "      <td>blue</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>michael</td>\n",
       "      <td>bloomberg</td>\n",
       "      <td>False</td>\n",
       "      <td>mich</td>\n",
       "      <td>hael</td>\n",
       "      <td>bloo</td>\n",
       "      <td>berg</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001930</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>tom</td>\n",
       "      <td>steyer</td>\n",
       "      <td>False</td>\n",
       "      <td>tom</td>\n",
       "      <td>tom</td>\n",
       "      <td>stey</td>\n",
       "      <td>eyer</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>timothy</td>\n",
       "      <td>mellon</td>\n",
       "      <td>False</td>\n",
       "      <td>timo</td>\n",
       "      <td>othy</td>\n",
       "      <td>mell</td>\n",
       "      <td>llon</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.005252</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.044110</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>miriam</td>\n",
       "      <td>adelson</td>\n",
       "      <td>False</td>\n",
       "      <td>miri</td>\n",
       "      <td>riam</td>\n",
       "      <td>adel</td>\n",
       "      <td>lson</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.002618</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588744</th>\n",
       "      <td>3588932</td>\n",
       "      <td>elizabeth</td>\n",
       "      <td>english</td>\n",
       "      <td>False</td>\n",
       "      <td>eliz</td>\n",
       "      <td>beth</td>\n",
       "      <td>engl</td>\n",
       "      <td>lish</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.002251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588745</th>\n",
       "      <td>3588933</td>\n",
       "      <td>linda</td>\n",
       "      <td>rapp</td>\n",
       "      <td>False</td>\n",
       "      <td>lind</td>\n",
       "      <td>inda</td>\n",
       "      <td>rapp</td>\n",
       "      <td>rapp</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588746</th>\n",
       "      <td>3588934</td>\n",
       "      <td>julie</td>\n",
       "      <td>oldham</td>\n",
       "      <td>False</td>\n",
       "      <td>juli</td>\n",
       "      <td>ulie</td>\n",
       "      <td>oldh</td>\n",
       "      <td>dham</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.009736</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588747</th>\n",
       "      <td>3588935</td>\n",
       "      <td>nancy</td>\n",
       "      <td>martin</td>\n",
       "      <td>False</td>\n",
       "      <td>nanc</td>\n",
       "      <td>ancy</td>\n",
       "      <td>mart</td>\n",
       "      <td>rtin</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3588748</th>\n",
       "      <td>3588936</td>\n",
       "      <td>sue</td>\n",
       "      <td>corradetti</td>\n",
       "      <td>False</td>\n",
       "      <td>sue</td>\n",
       "      <td>sue</td>\n",
       "      <td>corr</td>\n",
       "      <td>etti</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3588749 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  firstname    lastname  indian first_name_f4 first_name_l4  \\\n",
       "0              1    actblue     actblue   False          actb          blue   \n",
       "1              2    michael   bloomberg   False          mich          hael   \n",
       "2              3        tom      steyer   False           tom           tom   \n",
       "3              4    timothy      mellon   False          timo          othy   \n",
       "4              5     miriam     adelson   False          miri          riam   \n",
       "...          ...        ...         ...     ...           ...           ...   \n",
       "3588744  3588932  elizabeth     english   False          eliz          beth   \n",
       "3588745  3588933      linda        rapp   False          lind          inda   \n",
       "3588746  3588934      julie      oldham   False          juli          ulie   \n",
       "3588747  3588935      nancy      martin   False          nanc          ancy   \n",
       "3588748  3588936        sue  corradetti   False           sue           sue   \n",
       "\n",
       "        last_name_f4 last_name_l4  pop_ln_indian  pop_fn_indian  \\\n",
       "0               actb         blue       0.000000       0.000000   \n",
       "1               bloo         berg       0.000000       0.001818   \n",
       "2               stey         eyer       0.000000       0.000903   \n",
       "3               mell         llon       0.000000       0.001856   \n",
       "4               adel         lson       0.000000       0.000805   \n",
       "...              ...          ...            ...            ...   \n",
       "3588744         engl         lish       0.001623       0.002059   \n",
       "3588745         rapp         rapp       0.000000       0.001796   \n",
       "3588746         oldh         dham       0.000000       0.001888   \n",
       "3588747         mart         rtin       0.000873       0.001560   \n",
       "3588748         corr         etti       0.000000       0.001309   \n",
       "\n",
       "         best_evidence_indian  pop_ln_indian_f4  pop_fn_indian_f4  \\\n",
       "0                    0.000000          0.000000          0.000000   \n",
       "1                    0.001818          0.000000          0.001930   \n",
       "2                    0.000903          0.000000          0.000903   \n",
       "3                    0.001856          0.005252          0.001843   \n",
       "4                    0.000805          0.002618          0.000775   \n",
       "...                       ...               ...               ...   \n",
       "3588744              0.002059          0.001106          0.002022   \n",
       "3588745              0.001796          0.000000          0.001779   \n",
       "3588746              0.001888          0.000000          0.002424   \n",
       "3588747              0.001560          0.000792          0.001580   \n",
       "3588748              0.001309          0.000000          0.001309   \n",
       "\n",
       "         pop_ln_indian_l4  pop_fn_indian_l4  last_name_low  first_name_low  \n",
       "0                0.000000          0.000000              1               1  \n",
       "1                0.000404          0.001825              0               0  \n",
       "2                0.000175          0.000903              0               0  \n",
       "3                0.044110          0.002094              0               0  \n",
       "4                0.000659          0.003446              0               0  \n",
       "...                   ...               ...            ...             ...  \n",
       "3588744          0.002060          0.002251              0               0  \n",
       "3588745          0.000000          0.002167              0               0  \n",
       "3588746          0.009736          0.001882              0               0  \n",
       "3588747          0.000780          0.001601              0               0  \n",
       "3588748          0.007962          0.001309              1               0  \n",
       "\n",
       "[3588749 rows x 17 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create_train_features(str(year))\n",
    "output_path = f\"../data/donors{year}_USIN_features.csv\"\n",
    "features = pd.read_csv(output_path)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_set_indian(features, num_rows=100000, full_data=False, first_name_encoder=None, last_name_encoder=None):\n",
    "\n",
    "    features = features.dropna(subset=['firstname', 'lastname', 'indian'])\n",
    "    features.fillna(0, inplace=True)\n",
    "    \n",
    "    if not full_data:\n",
    "        features = features.sample(n=num_rows, random_state=42)\n",
    "    \n",
    "    features.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Preprocess name embeddings upfront\n",
    "    if first_name_encoder is None:\n",
    "        first_name_encoder = LabelEncoder()\n",
    "        X_first_name = first_name_encoder.fit_transform(features['firstname'].fillna('unknown'))\n",
    "    else:\n",
    "        # For test data, use existing encoder and map unseen names to 'unknown'\n",
    "        try:\n",
    "            X_first_name = first_name_encoder.transform(features['firstname'].fillna('unknown'))\n",
    "        except ValueError:\n",
    "            # Handle unseen names by mapping to 'unknown'\n",
    "            features['firstname'] = features['firstname'].apply(\n",
    "                lambda x: x if x in first_name_encoder.classes_ else 'unknown'\n",
    "            )\n",
    "            X_first_name = first_name_encoder.transform(features['firstname'])\n",
    "    \n",
    "    if last_name_encoder is None:\n",
    "        last_name_encoder = LabelEncoder()\n",
    "        X_last_name = last_name_encoder.fit_transform(features['lastname'].fillna('unknown'))\n",
    "    else:\n",
    "        # For test data, use existing encoder and map unseen names to 'unknown'\n",
    "        try:\n",
    "            X_last_name = last_name_encoder.transform(features['lastname'].fillna('unknown'))\n",
    "        except ValueError:\n",
    "            # Handle unseen names by mapping to 'unknown'\n",
    "            features['lastname'] = features['lastname'].apply(\n",
    "                lambda x: x if x in last_name_encoder.classes_ else 'unknown'\n",
    "            )\n",
    "            X_last_name = last_name_encoder.transform(features['lastname'])\n",
    "    \n",
    "    # Add encoded names as features\n",
    "    features['first_name_encoded'] = X_first_name\n",
    "    features['last_name_encoded'] = X_last_name\n",
    "    \n",
    "    # Keep relevant columns\n",
    "    main_features = features[['firstname', 'lastname', 'indian', 'id', 'first_name_encoded', 'last_name_encoded']]\n",
    "    y = main_features['indian'].astype(int)\n",
    "    X = main_features.drop(['id', 'firstname', 'lastname', 'indian'], axis=1, errors='ignore')\n",
    "    \n",
    "    print(f\"X shape = {X.shape}, y shape = {y.shape}\")\n",
    "    print(f\"Indian count: {y.sum()}, Non-Indian count: {len(y) - y.sum()}\")\n",
    "    \n",
    "    return X, y, main_features, first_name_encoder, last_name_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape = (3587209, 2), y shape = (3587209,)\n",
      "Indian count: 43220, Non-Indian count: 3543989\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name_encoded</th>\n",
       "      <th>last_name_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>656</td>\n",
       "      <td>2160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59248</td>\n",
       "      <td>39073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88498</td>\n",
       "      <td>383238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88136</td>\n",
       "      <td>262404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60162</td>\n",
       "      <td>2597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587204</th>\n",
       "      <td>24747</td>\n",
       "      <td>115509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587205</th>\n",
       "      <td>51619</td>\n",
       "      <td>325882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587206</th>\n",
       "      <td>42924</td>\n",
       "      <td>292638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587207</th>\n",
       "      <td>62628</td>\n",
       "      <td>251703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3587208</th>\n",
       "      <td>83699</td>\n",
       "      <td>77937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3587209 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         first_name_encoded  last_name_encoded\n",
       "0                       656               2160\n",
       "1                     59248              39073\n",
       "2                     88498             383238\n",
       "3                     88136             262404\n",
       "4                     60162               2597\n",
       "...                     ...                ...\n",
       "3587204               24747             115509\n",
       "3587205               51619             325882\n",
       "3587206               42924             292638\n",
       "3587207               62628             251703\n",
       "3587208               83699              77937\n",
       "\n",
       "[3587209 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y, main_features, first_name_encoder, last_name_encoder = process_data_set_indian(features, num_rows=1, full_data=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_indian_classifier(train_data_label, X_train, y_train, first_name_encoder, last_name_encoder, epochs=5):\n",
    "    print(\"date and time =\", datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "\n",
    "    best_loss = 999999999\n",
    "    patience = 5\n",
    "    patience_counter = 0\n",
    "    early_stop = False\n",
    "    batch_size = 1024\n",
    "    \n",
    "    first_name_vocab_size = len(first_name_encoder.classes_)\n",
    "    last_name_vocab_size = len(last_name_encoder.classes_)\n",
    "    print(f\"First name vocabulary size: {first_name_vocab_size}\")\n",
    "    print(f\"Last name vocabulary size: {last_name_vocab_size}\")\n",
    "    \n",
    "    X_numeric = X_train.values.astype(np.float32)\n",
    "    print(f\"Using {X_numeric.shape[1]} numeric features + character embeddings\")\n",
    "    \n",
    "    X_numeric_tensor = torch.tensor(X_numeric, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y_train.values.astype(np.float32), dtype=torch.float32)\n",
    "    first_name_encoded_idx = X_train.columns.get_loc('first_name_encoded')\n",
    "    last_name_encoded_idx = X_train.columns.get_loc('last_name_encoded')\n",
    "    \n",
    "    dataset = TensorDataset(X_numeric_tensor, y_tensor)\n",
    "    train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    numeric_dim = X_numeric.shape[1] - 2\n",
    "    embedding_dim = 32\n",
    "    hidden_dim = 64\n",
    "    \n",
    "    first_name_embedding = nn.Embedding(num_embeddings=first_name_vocab_size + 10, embedding_dim=embedding_dim)\n",
    "    last_name_embedding = nn.Embedding(num_embeddings=last_name_vocab_size + 10, embedding_dim=embedding_dim)\n",
    "    linear1 = nn.Linear(numeric_dim + 2 * embedding_dim, hidden_dim)\n",
    "    linear2 = nn.Linear(hidden_dim, 1)\n",
    "    relu = nn.ReLU()\n",
    "    sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    parameters = list(first_name_embedding.parameters()) + list(last_name_embedding.parameters()) + list(linear1.parameters()) + list(linear2.parameters())\n",
    "    \n",
    "    print(\"date and time =\", datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "    \n",
    "    criterion = torch.nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(parameters, lr=0.001)\n",
    "\n",
    "    iteration_list = []\n",
    "    loss_list = []\n",
    "    accuracy_list = []\n",
    "    average_loss = 0\n",
    "    iteration = 0\n",
    "\n",
    "    for epoch in range(int(epochs)):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (features_batch, labels) in enumerate(train_loader):\n",
    "            iteration = iteration + 1\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Split the batch into numeric features and encoded names\n",
    "            numeric_features = features_batch[:, [idx for idx in range(features_batch.shape[1]) \n",
    "                                              if idx not in [first_name_encoded_idx, last_name_encoded_idx]]]\n",
    "            first_name_ids = features_batch[:, first_name_encoded_idx].long()\n",
    "            last_name_ids = features_batch[:, last_name_encoded_idx].long()\n",
    "            \n",
    "            # Get embeddings\n",
    "            first_name_emb = first_name_embedding(first_name_ids)\n",
    "            last_name_emb = last_name_embedding(last_name_ids)\n",
    "            \n",
    "            # Combine features\n",
    "            combined = torch.cat([numeric_features, first_name_emb, last_name_emb], dim=1)\n",
    "            hidden = relu(linear1(combined))\n",
    "            outputs = sigmoid(linear2(hidden))\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted.squeeze() == labels).sum().item()\n",
    "            average_loss += loss.item()\n",
    "            \n",
    "            if iteration % 1024 == 0:\n",
    "                current_loss = average_loss / 1024 if average_loss > 0 else loss.item()\n",
    "                \n",
    "                # Check if loss improved\n",
    "                if current_loss < best_loss:\n",
    "                    best_loss = current_loss\n",
    "                    patience_counter = 0\n",
    "                    torch.save({\n",
    "                        'first_name_embedding': first_name_embedding.state_dict(),\n",
    "                        'last_name_embedding': last_name_embedding.state_dict(),\n",
    "                        'linear1': linear1.state_dict(),\n",
    "                        'linear2': linear2.state_dict(),\n",
    "                        'first_name_encoder_classes': first_name_encoder.classes_,\n",
    "                        'last_name_encoder_classes': last_name_encoder.classes_,\n",
    "                        'first_name_encoded_idx': first_name_encoded_idx,\n",
    "                        'last_name_encoded_idx': last_name_encoded_idx,\n",
    "                        'feature_columns': list(X_train.columns)\n",
    "                    }, f\"./models/indian_classifier_{train_data_label}_best.pt\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    print(f\"No improvement for {patience_counter}/{patience} iterations\")\n",
    "                    \n",
    "                # Check for early stopping\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"Early stopping triggered at iteration {iteration}\")\n",
    "                    early_stop = True\n",
    "                    break\n",
    "\n",
    "            # Add this at the end of the epoch loop\n",
    "            if early_stop:\n",
    "                break\n",
    "\n",
    "            if iteration % 1024 == 0:\n",
    "                iteration_list.append(iteration)\n",
    "                loss_list.append(average_loss / 1024)\n",
    "                accuracy = 100 * correct / total\n",
    "                print(\"Iteration: {}. Loss: {}. Accuracy: {}.\".format(iteration, average_loss / 1024, accuracy))\n",
    "                accuracy_list.append(accuracy)\n",
    "                total = 0\n",
    "                correct = 0\n",
    "                average_loss = 0\n",
    "\n",
    "    path = f\"./models/indian_classifier_{train_data_label}.pt\"\n",
    "    torch.save({\n",
    "        'first_name_embedding': first_name_embedding.state_dict(),\n",
    "        'last_name_embedding': last_name_embedding.state_dict(),\n",
    "        'linear1': linear1.state_dict(),\n",
    "        'linear2': linear2.state_dict(),\n",
    "        'first_name_encoder_classes': first_name_encoder.classes_,\n",
    "        'last_name_encoder_classes': last_name_encoder.classes_,\n",
    "        'first_name_encoded_idx': first_name_encoded_idx,\n",
    "        'last_name_encoded_idx': last_name_encoded_idx,\n",
    "        'feature_columns': list(X_train.columns)\n",
    "    }, path)\n",
    "\n",
    "    plt.plot(iteration_list, loss_list)\n",
    "    plt.xlabel('Number of Iterations')\n",
    "    plt.ylabel('Loss on Training Set')\n",
    "    plt.title('Indian Classifier - Logistic Regression')\n",
    "    plt.savefig(f\"../images/ethnicia_{train_data_label}_loss.png\")\n",
    "    plt.clf()\n",
    "\n",
    "    plt.plot(iteration_list, accuracy_list)\n",
    "    plt.xlabel('Number of Iterations')\n",
    "    plt.ylabel('Accuracy on Training Set')\n",
    "    plt.title('Indian Classifier - Logistic Regression')\n",
    "    plt.savefig(f\"../images/ethnicia_{train_data_label}_accuracy.png\")\n",
    "    plt.clf()\n",
    "    \n",
    "    print(\"date and time =\", datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "    print(f\"Training completed. Model saved as: indian_classifier_{train_data_label}.pt\")\n",
    "    \n",
    "    return {\n",
    "        'first_name_embedding': first_name_embedding,\n",
    "        'last_name_embedding': last_name_embedding,\n",
    "        'linear1': linear1,\n",
    "        'linear2': linear2\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_indian_classifier(model_dict, X_test, y_test, first_name_encoder, last_name_encoder):\n",
    "    \n",
    "    X_numeric_tensor = torch.tensor(X_test.values.astype(np.float32), dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y_test.values.astype(np.float32), dtype=torch.float32)\n",
    "    \n",
    "    # Get the indices of encoded name columns from the saved model info\n",
    "    first_name_encoded_idx = X_test.columns.get_loc('first_name_encoded')\n",
    "    last_name_encoded_idx = X_test.columns.get_loc('last_name_encoded')\n",
    "    \n",
    "    # Set model to eval mode\n",
    "    print(model_dict)\n",
    "    model_dict['first_name_embedding'].eval()\n",
    "    model_dict['last_name_embedding'].eval()\n",
    "    model_dict['linear1'].eval()\n",
    "    model_dict['linear2'].eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        numeric_features = X_numeric_tensor[:, [idx for idx in range(X_numeric_tensor.shape[1]) \n",
    "                                             if idx not in [first_name_encoded_idx, last_name_encoded_idx]]]\n",
    "        first_name_ids = X_numeric_tensor[:, first_name_encoded_idx].long()\n",
    "        last_name_ids = X_numeric_tensor[:, last_name_encoded_idx].long()\n",
    "        \n",
    "        # Forward pass\n",
    "        first_name_emb = model_dict['first_name_embedding'](first_name_ids)\n",
    "        last_name_emb = model_dict['last_name_embedding'](last_name_ids)\n",
    "        combined = torch.cat([numeric_features, first_name_emb, last_name_emb], dim=1)\n",
    "        hidden = torch.relu(model_dict['linear1'](combined))\n",
    "        outputs = torch.sigmoid(model_dict['linear2'](hidden))\n",
    "        \n",
    "        predictions = (outputs > 0.5).float()\n",
    "        correct = (predictions.squeeze() == y_tensor).sum().item()\n",
    "        total = y_tensor.size(0)\n",
    "        accuracy = 100 * correct / total\n",
    "        \n",
    "        true_positives = ((predictions.squeeze() == 1) & (y_tensor == 1)).sum().item()\n",
    "        false_positives = ((predictions.squeeze() == 1) & (y_tensor == 0)).sum().item()\n",
    "        true_negatives = ((predictions.squeeze() == 0) & (y_tensor == 0)).sum().item()\n",
    "        false_negatives = ((predictions.squeeze() == 0) & (y_tensor == 1)).sum().item()\n",
    "        \n",
    "        precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "        recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        test_metrics = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1_score': f1_score,\n",
    "            'true_positives': true_positives,\n",
    "            'false_positives': false_positives,\n",
    "            'true_negatives': true_negatives,\n",
    "            'false_negatives': false_negatives,\n",
    "            'total_samples': total\n",
    "        }\n",
    "    \n",
    "    return test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_indian_classifier(train_data_label, X, y, test_size=0.3, epochs=50):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    model_dict = train_indian_classifier(train_data_label, X_train, y_train, first_name_encoder, last_name_encoder, epochs=epochs)\n",
    "    \n",
    "    print(\"\\nTesting model...\")\n",
    "    test_metrics = test_indian_classifier(model_dict, X_test, y_test, first_name_encoder, last_name_encoder)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TEST RESULTS:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Accuracy: {test_metrics['accuracy']:.2f}%\")\n",
    "    print(f\"Precision: {test_metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {test_metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {test_metrics['f1_score']:.4f}\")\n",
    "    print(f\"True Positives: {test_metrics['true_positives']}\")\n",
    "    print(f\"False Positives: {test_metrics['false_positives']}\")\n",
    "    print(f\"True Negatives: {test_metrics['true_negatives']}\")\n",
    "    print(f\"False Negatives: {test_metrics['false_negatives']}\")\n",
    "    \n",
    "    return model_dict, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "date and time = 25/08/2025 13:45:25\n",
      "First name vocabulary size: 98623\n",
      "Last name vocabulary size: 450582\n",
      "Using 2 numeric features + character embeddings\n",
      "date and time = 25/08/2025 13:45:26\n",
      "Iteration: 1024. Loss: 0.08619794135847769. Accuracy: 98.06890487670898.\n",
      "Iteration: 2048. Loss: 0.04049863769159856. Accuracy: 98.97441864013672.\n",
      "Iteration: 3072. Loss: 0.030566009686936013. Accuracy: 99.20076484248789.\n",
      "Iteration: 4096. Loss: 0.025415988099211972. Accuracy: 99.28693771362305.\n",
      "Iteration: 5120. Loss: 0.022274870089177057. Accuracy: 99.47064836448598.\n",
      "Iteration: 6144. Loss: 0.018684919646148046. Accuracy: 99.47052001953125.\n",
      "Iteration: 7168. Loss: 0.017270058229769347. Accuracy: 99.50103759765625.\n",
      "Iteration: 8192. Loss: 0.014756163797528643. Accuracy: 99.58627982442977.\n",
      "Iteration: 9216. Loss: 0.013528279008596655. Accuracy: 99.6027946472168.\n",
      "Iteration: 10240. Loss: 0.012004251794678567. Accuracy: 99.68216084988318.\n",
      "Iteration: 11264. Loss: 0.010408573815197997. Accuracy: 99.68252182006836.\n",
      "No improvement for 1/3 iterations\n",
      "Iteration: 12288. Loss: 0.010515222350136355. Accuracy: 99.7367527173913.\n",
      "Iteration: 13312. Loss: 0.008216285877438168. Accuracy: 99.74899291992188.\n",
      "Iteration: 14336. Loss: 0.008068415977163568. Accuracy: 99.75423812866211.\n",
      "Iteration: 15360. Loss: 0.00721110426627547. Accuracy: 99.80605651285046.\n",
      "Iteration: 16384. Loss: 0.006422141572443252. Accuracy: 99.79915618896484.\n",
      "Iteration: 17408. Loss: 0.006120993332217495. Accuracy: 99.85413370253164.\n",
      "Iteration: 18432. Loss: 0.005082079306134801. Accuracy: 99.83749389648438.\n",
      "No improvement for 1/3 iterations\n",
      "Iteration: 19456. Loss: 0.005168218433567517. Accuracy: 99.83596801757812.\n",
      "Iteration: 20480. Loss: 0.003885649237815869. Accuracy: 99.88237897926402.\n",
      "No improvement for 1/3 iterations\n",
      "Iteration: 21504. Loss: 0.00398541870237068. Accuracy: 99.8687744140625.\n",
      "Iteration: 22528. Loss: 0.0035422029897631546. Accuracy: 99.9040760116408.\n",
      "Iteration: 23552. Loss: 0.0029795754584540646. Accuracy: 99.90463256835938.\n",
      "No improvement for 1/3 iterations\n",
      "Iteration: 24576. Loss: 0.0030641207954289484. Accuracy: 99.92357336956522.\n",
      "Iteration: 25600. Loss: 0.002208112734898293. Accuracy: 99.92666244506836.\n",
      "No improvement for 1/3 iterations\n",
      "Iteration: 26624. Loss: 0.002384440834212853. Accuracy: 99.92151260375977.\n",
      "Iteration: 27648. Loss: 0.0018790188363340121. Accuracy: 99.94742716165413.\n",
      "Iteration: 28672. Loss: 0.0016970727924849882. Accuracy: 99.94144439697266.\n",
      "Iteration: 29696. Loss: 0.001680434396913455. Accuracy: 99.96920072115384.\n",
      "Iteration: 30720. Loss: 0.0012919106316768847. Accuracy: 99.95546340942383.\n",
      "No improvement for 1/3 iterations\n",
      "Iteration: 31744. Loss: 0.0013853154938843204. Accuracy: 99.94869232177734.\n",
      "Iteration: 32768. Loss: 0.0010197074095046332. Accuracy: 99.9700031996587.\n",
      "Iteration: 33792. Loss: 0.0010039268766925957. Accuracy: 99.9643325805664.\n",
      "Iteration: 34816. Loss: 0.0009416254190401929. Accuracy: 99.97259856276371.\n",
      "Iteration: 35840. Loss: 0.0007311478039007113. Accuracy: 99.97377395629883.\n",
      "No improvement for 1/3 iterations\n",
      "Iteration: 36864. Loss: 0.0008069562733128421. Accuracy: 99.98301630434783.\n",
      "Iteration: 37888. Loss: 0.0005013808711151757. Accuracy: 99.98369216918945.\n",
      "No improvement for 1/3 iterations\n",
      "Iteration: 38912. Loss: 0.0006703759117110408. Accuracy: 99.97625350952148.\n",
      "Iteration: 39936. Loss: 0.0004930566234682132. Accuracy: 99.98736714207848.\n",
      "Iteration: 40960. Loss: 0.0004835576059698532. Accuracy: 99.98321533203125.\n",
      "No improvement for 1/3 iterations\n",
      "Iteration: 41984. Loss: 0.0005462246393868053. Accuracy: 99.98826744699646.\n",
      "Iteration: 43008. Loss: 0.00035851129110686664. Accuracy: 99.9882698059082.\n",
      "No improvement for 1/3 iterations\n",
      "Iteration: 44032. Loss: 0.0004603919005760071. Accuracy: 99.9842643737793.\n",
      "Iteration: 45056. Loss: 0.000299468803190317. Accuracy: 99.9911221590909.\n",
      "No improvement for 1/3 iterations\n",
      "Iteration: 46080. Loss: 0.0004039953702615895. Accuracy: 99.98598098754883.\n",
      "No improvement for 2/3 iterations\n",
      "Iteration: 47104. Loss: 0.00036332663012994537. Accuracy: 99.99017542756539.\n",
      "Iteration: 48128. Loss: 0.00026841888586917606. Accuracy: 99.99027252197266.\n",
      "No improvement for 1/3 iterations\n",
      "Iteration: 49152. Loss: 0.00036530411260404794. Accuracy: 99.98938519021739.\n",
      "No improvement for 2/3 iterations\n",
      "Iteration: 50176. Loss: 0.00029231805833662694. Accuracy: 99.99008178710938.\n",
      "No improvement for 3/3 iterations\n",
      "Early stopping triggered at iteration 51200\n",
      "date and time = 25/08/2025 14:34:50\n",
      "Training completed. Model saved as: indian_classifier_20.pt\n",
      "\n",
      "Testing model...\n",
      "{'first_name_embedding': Embedding(98633, 32), 'last_name_embedding': Embedding(450592, 32), 'linear1': Linear(in_features=64, out_features=64, bias=True), 'linear2': Linear(in_features=64, out_features=1, bias=True)}\n",
      "\n",
      "==================================================\n",
      "TEST RESULTS:\n",
      "==================================================\n",
      "Accuracy: 99.01%\n",
      "Precision: 0.5633\n",
      "Recall: 0.8108\n",
      "F1 Score: 0.6647\n",
      "True Positives: 10513\n",
      "False Positives: 8151\n",
      "True Negatives: 1055046\n",
      "False Negatives: 2453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model, metrics = train_and_test_indian_classifier(str(year), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
